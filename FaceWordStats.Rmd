---
title: "FaceWord Project -- Data Analysis"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%b %d %Y')`"
output:
  html_document:
    df_print: paged
    number_sections: true
    toc: true
    toc_depth: 6
    toc_float: 
      collapsed: true
      smooth_scroll: false
    includes:
      after_body: Utilities/footer.html
---

# Introduction
## Usage of this file
This file serves to be a supplementary document that describes all the statistics results performed for this project. It may help to test some new questions that are not included in the corresponding slides. 

## Experiment designs
This file displays the results of the FaceWord project (data collected at NYU). There are two experiments in this project. In Experiment 1, Chinese participants viewed Chinese faces and characters in four conditions (*Layout*: intact, exchange [top and bottom parts were switched], top and bottom) and completed an additional localizer (Chinese faces, Chinese characters, objects, scrambled objects). In Experiment 2, English speakers viewed Chinese characters and English words in four conditions (*Layout*: intact, exchange, top [top parts of Chinese characters; left two letters for English words] and bottom [bottom parts of Chinese characters; right four letters for English words]) and completed an additional localizer (Caucasian faces, English words, objects, scrambled objects).

## Introduction to the analyses included in this file
For the **main runs**, analysis is conducted for each ROI separately (FFA1, FFA2, VWFA, LOC).   
For each ROI, three analyses are performed: 

1. Univariate analysis (Repeated-measures ANOVA) is performed to compare the neural responses (beta values) of different conditions.
    + E1: 2(Chinese faces vs. Chinese Characters) * 4 (intact, exchange, top vs. bottom); 
    + E2: 2(Chinese characters vs. English words) * 4 (intact, exchange, top vs. bottom).
2. Multivariate pattern analysis (MVPA) with `libsvm` is used to decode different condition pairs (see below) and one-tail one-sample t-tests is used to test if the pair of conditions can be decoded [whether the accuracy is significantly larger than the chancel level (0.5); one-tail one-sample t-tests]. Leave-one(-run)-out cross-validation is applied. No normalized or demean were used.
    + Pairs in E1: 
        + face_intact vs. word_intact;
        + face_intact vs. face_exchange;
        + face_top vs. face_bottom;
        + word_intact vs. word_exchange;
        + word_top vs. word_bottom.
    + Pairs in E2:
        + English_intact vs. Chinese_intact;
        + English_intact vs. English_exchange;
        + English_left vs. English_right;
        + Chinese_intact vs. Chinese_exchange;
        + Chinese_top vs. Chinese_bottom.
3. Similarity of top+bottom to intact vs. exchange: The dependent variable is the probability of top+bottom was decoded as Exchange conditions. Two-tail one-sample t-tests is used to test if top+bottom is more similar to exchange relative to intact.
    + If the pattern of top+bottom is more similar to that of exchange relative to intact, the probability (of being decoded as exchange) should be *significantly larger* than the chance level (0.5).
    + If the pattern of top+bottom is more similar to that of intact relative to exchange, the probability (of being decoded as exchange) should be *significantly smaller* than the chance level (0.5).
  
## How the labels are defined for each ROI?
1. Identify the vertex whose beta value is larger than the surrounding vertices (i.e., the local maxima) for each ROI based on the reference coordinates in previous literature.
2. Dilate the region centering at the local maxima and only keep 50% of the "peripheral" vertices whose response were larger. This step is iterated until the size of the ROI reaches the pre-defined size (100mm^2), during which the vertices are masked by a pre-defined label at the threshold of p < .05. In other words, the p-values for all vertices in the labels are smaller than .05 (uncorrected).

## How is the probability of top+bottom being decoded as exchange calculated?
The probability was estimated for each particiapnt separately:

1. The patterns of top and bottom are combined with three different weights (0.5/0.5, 0.25/0.75, 0.75/0.25).
2. Supported Vector Machine (`libsvm`) is trained with the patterns of intact vs. exchange (10 runs).
3. The trained model is used to predict the probability of the combined patterns being decoded as exchange [for each run separately]. 
4. The probability of top+bottom being decoded as exchange for each participant is calculated by averaging the probability for each run.

# Preparations
```{r general setting for this document, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)  # hide all warnings
knitr::opts_chunk$set(message = FALSE)  # hide all messages
# knitr::opts_chunk$set(echo = FALSE)  # hide all codes and only show output
# knitr::opts_chunk$set(fig.width = 11)  

options(width = 450)
showAll = TRUE  # if show steps for cleaning 
```

```{r preparation, include=FALSE}
# load library
library(tidyverse)
library(afex)
library(lme4)
library(lmerTest)
library(emmeans)
library(ggpubr)
library(tools)

```

```{r include=showAll}
# set the order of levels in factors
loc_order <- c("face", "object", "word", "scrambled")

faceword_order <- c("faces", "words")
words_order <- c("English", "Chinese")
layout_order <- c("intact", "exchange", "top", "bottom")
roi_order <- c("FFA1", "FFA2", "VWFA", "LO")

label_FFA1 <- c("roi.lh.f-vs-o.ffa1.label", "roi.rh.f-vs-o.ffa1.label")
label_FFA2 <- c("roi.lh.f-vs-o.ffa2.label", "roi.rh.f-vs-o.ffa2.label")
label_VWFA <- "roi.lh.word-vs-face-object-scrambled.label"
label_LO <- c("roi.lh.o-vs-scr.label", "roi.rh.o-vs-scr.label")

# criterion of vertex number
nVtx_size_min <- 30  # mm^2

```

```{r setting for plots, include=showAll}
# set up the theme for plot and rainclound plot
# load all the R files in "Utilities/"
tmp <- sapply(list.files('Utilities', "*.R", full.names = TRUE, recursive = TRUE), source)

activationUL <- 2.75
onesample0 <- 0.3 # the staring point of y axis (for one-sample t-tests)
nDigitals <- 3 # number of digitials of p-values in plots

```

# Experiment 1: Chinese faces and Chinese characters for Chinese participants
## Load and clean data 
```{r assign filenames E1, include=showAll}
pair_order_E1 <- c("face_intact-word_intact",
                   "face_intact-face_exchange",
                   "face_top-face_bottom",
                   "word_intact-word_exchange",
                   "word_top-word_bottom")

```

### Label (ROI) information
```{r label information E1, message=FALSE}
df_label <- read_csv(file.path("data", "faceword_E1_Label_HJ.csv")) %>% 
  mutate(roi = str_remove(Label, "roi."),
         roi = str_remove(roi, ".label")) %>% 
  mutate(Subject = str_replace(SubjCode, "\\_.*", ""))

# df_label %>% head()
```

#### Size of labels
```{r size (mm2) of labels for each subject E1}
df_label %>% 
  select(SubjCode, roi, Size) %>% 
  pivot_wider(names_from = roi, values_from = Size) %>% 
  arrange(SubjCode)
```
The above table displays the size (in mm2) of each label for each participant. (NA denotes that this label is not available for that particiapnt.)

#### Number of vertices for each label
```{r Number of vertices for each label E1}
df_label %>% 
  select(SubjCode, roi, NVtxs) %>% 
  pivot_wider(names_from = roi, values_from = NVtxs) %>% 
  arrange(SubjCode)
```
The above table displays the number of vertices for each label and each participant. (NA denotes that this label is not available for that particiapnt.)


#### Number of participants for each ROI
```{r Number of available labels for each ROI E1}
df_label %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 
```

#### Number of remaining participants
```{r Number of remaining participants E1}

df_nlabel <- df_label %>% 
  filter(Size > nVtx_size_min) %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 

df_nlabel
```
The above table dispalys the number of participants included in the following analyses for each ROI. (VWFA is only found on the left hemisphere.)

### Data for univariate analyses
```{r load data file for univariate analysis E1, message=FALSE, include=showAll}
# load data file from functional scans for univerate analysis
df_uni_E1 <- read_csv(file.path("data", "faceword_E1_Uni_HJ.csv"))

head(df_uni_E1)
```

```{r clean the univariate data E1, include=showAll}
df_clean_uni_E1 <- {
  df_uni_E1 %>% 
    filter(Response != "NaN") %>% 
    separate(Condition, c("FaceWord", "Layout"), "_") %>% # separate the conditions into two IVs
    mutate(FaceWord = gsub("face", "faces", FaceWord),
           FaceWord = gsub("word", "words", FaceWord),  
           Layout = factor(Layout, levels = layout_order), # convert the two IVs to factors
           Hemisphere = if_else(grepl("lh", Label), "left", if_else(grepl("rh", Label), "right", "NA"))) %>% 
    select(Hemisphere, Label, SessCode, FaceWord, Layout, Response) %>% 
    mutate(Subject = str_replace(SessCode, "\\_.*", "")) %>% 
    left_join(df_label, by = c("Label", "Subject")) %>% 
    filter(Size > nVtx_size_min)
}

head(df_clean_uni_E1)
```

### Data of decoding
```{r load data file from cosmoMVPA E1, message=FALSE, include=showAll}
df_decode_E1 <- read_csv(file.path("data", "faceword_E1_Decode_noz.csv"))

head(df_decode_E1)
```

```{r clean the cosmoMVPA data E1, include=showAll}
df_clean_decode_E1 <- df_decode_E1 %>% 
  select(Label, SessCode, ClassifyPair, ACC) %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), "left", 
                              if_else(grepl("rh", Label), "right", "NA")),
         Subject = str_remove(SessCode, "\\_.*")) %>% 
  left_join(df_label, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_decode_acc_E1 <- df_clean_decode_E1 %>% 
  group_by(Hemisphere, Label, SessCode, ClassifyPair) %>% # divide the data into groups by these columns 
  summarize(Accuracy = mean(ACC), Count = n()) %>% 
  ungroup()

df_decode_acc_E1
```

### Data for the Similarity of top + bottom
```{r Data for the Similarity of top + bottom E1, message=FALSE, include=showAll}
df_simi <- read_csv(file.path("data", "faceword_E1_Similarity_noz.csv"))

head(df_simi)
```

```{r clean the similarity data E1, include=showAll}

df_clean_simi_E1 <- df_simi %>% 
  mutate(asExchange = if_else(grepl("exchange", PredictCond), 1, 0),  # binary prediction
         pExchange = Probability_2,  # probability prediction
         Subject = str_remove(SessCode, "\\_.*")) %>% 
  left_join(df_label, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_rate_simi_E1 <- df_clean_simi_E1 %>% 
  group_by(SessCode, Label, ClassPair_1, Combination) %>% 
  summarize(binaryAsExchange = mean(asExchange),
            pAsExchange = mean(pExchange),
            RateAsExchange = pAsExchange) %>%  # use the probability instead of the categorical prediction
  ungroup() %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), 'left', if_else(grepl("rh", Label), "right", "NA")))

head(df_rate_simi_E1)

```

## Label:FFA1
```{r only keep data for FFA1 E1}
# only keep data for these two labels
df_uni_E1_FFA1 <- filter(df_clean_uni_E1, Label %in% label_FFA1)
df_decode_E1_FFA1 <- filter(df_decode_acc_E1, Label %in% label_FFA1)
df_simi_E1_FFA1 <- filter(df_rate_simi_E1, Label %in% label_FFA1)

df_uni_E1_FFA1 %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left FFA1
###### 4 * 2
```{r anova for univariate E1 FFA1 left}
anova_E1_lFFA1 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA1, Label == label_FFA1[[1]]))

anova_E1_lFFA1
```

```{r estimated marginal means for univairate E1 lFFA1}
emm_aov_E1_lFFA1 <- emmeans(anova_E1_lFFA1, ~ FaceWord * Layout)

emm_aov_E1_lFFA1 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_lFFA1}
contrast(emmeans(emm_aov_E1_lFFA1, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_lFFA1, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_lFFA1}
contr_aov_E1_lFFA1 <- contrast(emm_aov_E1_lFFA1, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_lFFA1
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E1_lFFA1_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA1, 
                                         Label == label_FFA1[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E1_lFFA1_ie, "pes")
```

```{r}
emm_E1_lFFA1_ie <- emmeans(anova_E1_lFFA1_ie, ~ FaceWord + Layout)
(simple_E1_lFFA1_ie <- pairs(emm_E1_lFFA1_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_lFFA1_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA1, 
                                         Label == label_FFA1[[1]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_lFFA1_tb, "pes")
```

```{r}
emm_E1_lFFA1_tb <- emmeans(anova_E1_lFFA1_tb, ~ FaceWord + Layout)
(simple_E1_lFFA1_tb <- pairs(emm_E1_lFFA1_tb, simple = "each", combine = TRUE, adjust = "none"))
```

##### Right FFA1
###### 4 * 2
```{r anova for univariate E1 FFA1 right}
anova_E1_rFFA1 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA1, Label == label_FFA1[[2]]))

anova_E1_rFFA1
```

```{r estimated marginal means for univairate E1 FFA1 right}
emm_aov_E1_rFFA1 <- emmeans(anova_E1_rFFA1, ~ FaceWord * Layout)

emm_aov_E1_rFFA1 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_rFFA1 right}
contrast(emmeans(emm_aov_E1_rFFA1, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_rFFA1, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_rFFA1 right}
contr_aov_E1_rFFA1 <- contrast(emm_aov_E1_rFFA1, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_rFFA1
```

###### 2 * 2
```{r}
anova_E1_rFFA1_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA1, 
                                      Label == label_FFA1[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E1_rFFA1_ie, "pes")
```

```{r}
emm_E1_rFFA1_ie <- emmeans(anova_E1_rFFA1_ie, ~ FaceWord + Layout) 
(simple_E1_rFFA1_ie <- pairs(emm_E1_rFFA1_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_rFFA1_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA1, 
                                         Label == label_FFA1[[2]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_rFFA1_tb, "pes")
```

```{r}
emm_E1_rFFA1_tb <- emmeans(anova_E1_rFFA1_tb, ~ FaceWord + Layout)
(simple_E1_rFFA1_tb <- pairs(emm_E1_rFFA1_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E1 (anova) FFA1, fig.asp = .8, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_aov_E1_lFFA1))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA1 <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E1_lFFA1), as.data.frame(emm_aov_E1_rFFA1)))

plot_uni_E1_FFA1 <- plot_uni(desp_uni_E1_FFA1, contr_aov_E1_lFFA1, contr_aov_E1_rFFA1, "FFA1")

# ggsave('plot_uni_E1_FFA1.png', plot_uni_E1_FFA1, width = 10, height = 10)
plot_uni_E1_FFA1
```
<br/>
The above figure shows the neural respones (beta values) in FFA1 for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals. 
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"


```{r plots for functional scans E1 (22 anova) FFA1 ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lFFA1_ie))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA1_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lFFA1_ie), as.data.frame(emm_E1_rFFA1_ie)))

plot_uni_E1_FFA1_ie <- plot_uni(desp_uni_E1_FFA1_ie, simple_E1_lFFA1_ie, simple_E1_rFFA1_ie, "FFA1", F)

# ggsave('plot_uni_E1_FFA1_ie.png', plot_uni_E1_FFA1_ie, width = 10, height = 5)
plot_uni_E1_FFA1_ie
```

```{r plots for functional scans E1 (22 anova) FFA1 tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lFFA1_tb))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA1_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lFFA1_tb), as.data.frame(emm_E1_rFFA1_tb)))

plot_uni_E1_FFA1_tb <- plot_uni(desp_uni_E1_FFA1_tb, simple_E1_lFFA1_tb, simple_E1_rFFA1_tb, "FFA1", F)

# ggsave('plot_uni_E1_FFA1_tb.png', plot_uni_E1_FFA1_tb, width = 10, height = 5)
plot_uni_E1_FFA1_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E1 FFA1}
# one-sample for results of decode E1 FFA1
one_decode_agg_E1_FFA1 <- {
  df_decode_E1_FFA1 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E1)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E1_FFA1
```

#### Plot
```{r plots for functional scans decode E1 (anova) FFA1, fig.asp=2, fig.width = 7}

plot_decode_E1_FFA1 <- plot_decode(one_decode_agg_E1_FFA1, "FFA1")

# ggsave('plot_decode_E1_FFA1.png', plot_decode_E1_FFA1, width = 6.5, height = 16)

plot_decode_E1_FFA1
```
<br/>
The above figure shows the decoding accuracy in FFA1 for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in FFA1}

one_simi_E1_FFA1 <- {
  df_simi_E1_FFA1 %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E1_FFA1

```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in FFA1, fig.asp=1, fig.width = 8}

plot_simi_E1_FFA1 <- plot_simi(one_simi_E1_FFA1, "FFA1")
# ggsave('plot_simi_E1_FFA1.png', plot_simi_E1_FFA1, width = 8, height = 10)

plot_simi_E1_FFA1
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in FFA1. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.

## Label:FFA2
```{r only keep data for FFA2 E1}
# only keep data for these two labels
df_uni_E1_FFA2 <- filter(df_clean_uni_E1, Label %in% label_FFA2)
df_decode_E1_FFA2 <- filter(df_decode_acc_E1, Label %in% label_FFA2)
df_simi_E1_FFA2 <- filter(df_rate_simi_E1, Label %in% label_FFA2)

df_uni_E1_FFA2 %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left FFA2
###### 4 * 2
```{r anova for univariate E1 FFA2 left}
anova_E1_lFFA2 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA2, Label == label_FFA2[[1]]))

anova_E1_lFFA2
```

```{r estimated marginal means for univairate E1 lFFA2}
emm_aov_E1_lFFA2 <- emmeans(anova_E1_lFFA2, ~ FaceWord * Layout)

emm_aov_E1_lFFA2 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_lFFA2}
contrast(emmeans(emm_aov_E1_lFFA2, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_lFFA2, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_lFFA2}
contr_aov_E1_lFFA2 <- contrast(emm_aov_E1_lFFA2, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_lFFA2
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E1_lFFA2_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA2, 
                                         Label == label_FFA2[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E1_lFFA2_ie, "pes")
```

```{r}
emm_E1_lFFA2_ie <- emmeans(anova_E1_lFFA2_ie, ~ FaceWord + Layout)
(simple_E1_lFFA2_ie <- pairs(emm_E1_lFFA2_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_lFFA2_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA2, 
                                         Label == label_FFA2[[1]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_lFFA2_tb, "pes")
```

```{r}
emm_E1_lFFA2_tb <- emmeans(anova_E1_lFFA2_tb, ~ FaceWord + Layout)
(simple_E1_lFFA2_tb <- pairs(emm_E1_lFFA2_tb, simple = "each", combine = TRUE, adjust = "none"))
```

##### Right FFA2
###### 4 * 2
```{r anova for univariate E1 FFA2 right}
anova_E1_rFFA2 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA2, Label == label_FFA2[[2]]))

anova_E1_rFFA2
```

```{r estimated marginal means for univairate E1 FFA2 right}
emm_aov_E1_rFFA2 <- emmeans(anova_E1_rFFA2, ~ FaceWord * Layout)

emm_aov_E1_rFFA2 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_rFFA2 right}
contrast(emmeans(emm_aov_E1_rFFA2, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_rFFA2, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_rFFA2 right}
contr_aov_E1_rFFA2 <- contrast(emm_aov_E1_rFFA2, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_rFFA2
```

###### 2 * 2
```{r}
anova_E1_rFFA2_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_FFA2, 
                                      Label == label_FFA2[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E1_rFFA2_ie, "pes")
```

```{r}
emm_E1_rFFA2_ie <- emmeans(anova_E1_rFFA2_ie, ~ FaceWord + Layout) 
(simple_E1_rFFA2_ie <- pairs(emm_E1_rFFA2_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_rFFA2_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_FFA2, 
                                         Label == label_FFA2[[2]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_rFFA2_tb, "pes")
```

```{r}
emm_E1_rFFA2_tb <- emmeans(anova_E1_rFFA2_tb, ~ FaceWord + Layout)
(simple_E1_rFFA2_tb <- pairs(emm_E1_rFFA2_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E1 (anova) FFA2, fig.asp = .8, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_aov_E1_lFFA2))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA2 <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E1_lFFA2), as.data.frame(emm_aov_E1_rFFA2)))

plot_uni_E1_FFA2 <- plot_uni(desp_uni_E1_FFA2, contr_aov_E1_lFFA2, contr_aov_E1_rFFA2, "FFA2")

# ggsave('plot_uni_E1_FFA2.png', plot_uni_E1_FFA2, width = 10, height = 10)

plot_uni_E1_FFA2
```
<br/>
The above figure shows the neural respones (beta values) in FFA2 for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

```{r plots for functional scans E1 (22 anova) FFA2 ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lFFA2_ie))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA2_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lFFA2_ie), as.data.frame(emm_E1_rFFA2_ie)))

plot_uni_E1_FFA2_ie <- plot_uni(desp_uni_E1_FFA2_ie, simple_E1_lFFA2_ie, simple_E1_rFFA2_ie, "FFA2", F)

# ggsave('plot_uni_E1_FFA2_ie.png', plot_uni_E1_FFA2_ie, width = 10, height = 5)
plot_uni_E1_FFA2_ie
```

```{r plots for functional scans E1 (22 anova) FFA2 tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lFFA2_tb))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_FFA2_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lFFA2_tb), as.data.frame(emm_E1_rFFA2_tb)))

plot_uni_E1_FFA2_tb <- plot_uni(desp_uni_E1_FFA2_tb, simple_E1_lFFA2_tb, simple_E1_rFFA2_tb, "FFA2", F)

# ggsave('plot_uni_E1_FFA2_tb.png', plot_uni_E1_FFA2_tb, width = 10, height = 5)
plot_uni_E1_FFA2_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E1 FFA2}
# one-sample for results of decode E1 FFA2
one_decode_agg_E1_FFA2 <- {
  df_decode_E1_FFA2 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E1)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E1_FFA2
```

#### Plot
```{r plots for functional scans decode E1 (anova) FFA2, fig.asp=2, fig.width = 7}
plot_decode_E1_FFA2 <- plot_decode(one_decode_agg_E1_FFA2, "FFA2")

# ggsave('plot_decode_E1_FFA2.png', plot_decode_E1_FFA2, width = 6.5, height = 16)
plot_decode_E1_FFA2
```
<br/>
The above figure shows the decoding accuracy in FFA2 for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in FFA2 E1}
# Similarity of top + bottom to intact vs. exchange in FFA
one_simi_E1_FFA2 <- {
  df_simi_E1_FFA2 %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E1_FFA2
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in FFA2, fig.asp=1, fig.width = 8}

plot_simi_E1_FFA2 <- plot_simi(one_simi_E1_FFA2, "FFA2")
# ggsave('plot_simi_E1_FFA2.png', plot_simi_E1_FFA2, width = 8, height = 10)

plot_simi_E1_FFA2
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in FFA2. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.


## Label: left Visual Word Form Area (VWFA)
```{r only keep data for VWFA E1}
# only keep data for these two labels
df_uni_E1_VWFA <- filter(df_clean_uni_E1, Label %in% label_VWFA)
df_decode_E1_VWFA <- filter(df_decode_acc_E1, Label %in% label_VWFA)
df_simi_E1_VWFA <- filter(df_rate_simi_E1, Label %in% label_VWFA)

# subjects used for each hemisphere
# unique(as.character((df_univar_agg_E1_VWFA %>% filter(Label == label_VWFA_E1))$SubjCode))

df_uni_E1_VWFA %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
###### 4 * 2
```{r anova for univariate E1 VWFA left}
anova_E1_VWFA <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E1_VWFA, Label == label_VWFA))

anova_E1_VWFA
```

```{r estimated marginal means for univairate E1 VWFA}
emm_aov_E1_VWFA <- emmeans(anova_E1_VWFA, ~ FaceWord * Layout)

emm_aov_E1_VWFA %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_VWFA}
contrast(emmeans(emm_aov_E1_VWFA, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_VWFA, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_VWFA}
contr_aov_E1_VWFA <- contrast(emm_aov_E1_VWFA, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_VWFA
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E1_VWFA_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_VWFA, 
                                         Label == label_VWFA[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E1_VWFA_ie, "pes")
```

```{r}
emm_E1_VWFA_ie <- emmeans(anova_E1_VWFA_ie, ~ FaceWord + Layout)
(simple_E1_VWFA_ie <- pairs(emm_E1_VWFA_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_VWFA_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_VWFA, 
                                         Label == label_VWFA[[1]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_VWFA_tb, "pes")
```

```{r}
emm_E1_VWFA_tb <- emmeans(anova_E1_VWFA_tb, ~ FaceWord + Layout)
(simple_E1_VWFA_tb <- pairs(emm_E1_VWFA_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E1 (anova) VWFA, fig.asp = 1, fig.width = 6}
nRow_E1 <-nrow(as.data.frame(emm_aov_E1_VWFA))
Hemisphere <- c(rep("left", nRow_E1))
desp_uni_E1_VWFA <- cbind(Hemisphere, as.data.frame(emm_aov_E1_VWFA))

plot_uni_E1_VWFA <- plot_uni_vwfa(desp_uni_E1_VWFA, contr_aov_E1_VWFA, "VWFA")

# ggsave('plot_uni_E1_VWFA.png', plot_uni_E1_VWFA, width = 5.5, height = 10)
plot_uni_E1_VWFA
```
<br/>
The above figure shows the neural respones (beta values) in VWFA for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: *, _p_ < .05

```{r plots for functional scans E1 (anova) VWFA ie, fig.asp = .5, fig.width = 6}
nRow_E1 <-nrow(as.data.frame(emm_E1_VWFA_ie))
Hemisphere <- c(rep("left", nRow_E1))
desp_uni_E1_VWFA_ie <- cbind(Hemisphere, as.data.frame(emm_E1_VWFA_ie))

plot_uni_E1_VWFA_ie <- plot_uni_vwfa(desp_uni_E1_VWFA_ie, simple_E1_VWFA_ie, "VWFA", FALSE)

# ggsave('plot_uni_E1_VWFA_ie.png', plot_uni_E1_VWFA_ie, width = 5.5, height = 10)
plot_uni_E1_VWFA_ie
```

```{r plots for functional scans E1 (anova) VWFA tb, fig.asp = .5, fig.width = 6}
nRow_E1 <-nrow(as.data.frame(emm_E1_VWFA_tb))
Hemisphere <- c(rep("left", nRow_E1))
desp_uni_E1_VWFA_tb <- cbind(Hemisphere, as.data.frame(emm_E1_VWFA_tb))

plot_uni_E1_VWFA_tb <- plot_uni_vwfa(desp_uni_E1_VWFA_tb, simple_E1_VWFA_tb, "VWFA", FALSE)

# ggsave('plot_uni_E1_VWFA_tb.png', plot_uni_E1_VWFA_tb, width = 5.5, height = 10)
plot_uni_E1_VWFA_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E1 VWFA}
# one-sample for results of decode E1 VWFA
one_decode_agg_E1_VWFA <- {
  df_decode_E1_VWFA %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E1)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E1_VWFA

```

#### Plot
```{r plots for functional scans decode E1 (anova) VWFA, fig.asp=4, fig.width = 4}

  
plot_decode_E1_VWFA <- plot_decode_vwfa(one_decode_agg_E1_VWFA, "VWFA")
# ggsave('plot_decode_E1_VWFA.png', plot_decode_E1_VWFA, width = 4, height = 16)

plot_decode_E1_VWFA
```
<br/>
The above figure shows the decoding accuracy in VWFA for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: ***, _p_ <.001

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in VWFA E1}
# Similarity of top + bottom to intact vs. exchange in VWFA
one_simi_E1_VWFA <- {
  df_simi_E1_VWFA %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E1_VWFA
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in VWFA, fig.asp=2, fig.width = 4}

plot_simi_E1_VWFA <- plot_simi_vwfa(one_simi_E1_VWFA, "VWFA")

# ggsave('plot_simi_E1_VWFA.png', plot_simi_E1_VWFA, width = 4.25, height = 10)
plot_simi_E1_VWFA
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in VWFA. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.

## Label:Lateral Occipital Cortex
```{r only keep data for LO E1}
# only keep data for these two labels
df_uni_E1_LO <- filter(df_clean_uni_E1, Label %in% label_LO)
df_decode_E1_LO <- filter(df_decode_acc_E1, Label %in% label_LO)
df_simi_E1_LO <- filter(df_rate_simi_E1, Label %in% label_LO)

df_uni_E1_LO %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left LO
###### 4 * 2
```{r anova for univariate E1 LO left}
anova_E1_lLO <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E1_LO, Label == label_LO[[1]]))

anova_E1_lLO
```

```{r estimated marginal means for univairate E1 lLO}
emm_aov_E1_lLO <- emmeans(anova_E1_lLO, ~ FaceWord * Layout)

emm_aov_E1_lLO %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_lLO}
contrast(emmeans(emm_aov_E1_lLO, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_lLO, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_lLO}
contr_aov_E1_lLO <- contrast(emm_aov_E1_lLO, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_lLO
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E1_lLO_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_LO, 
                                         Label == label_LO[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E1_lLO_ie, "pes")
```

```{r}
emm_E1_lLO_ie <- emmeans(anova_E1_lLO_ie, ~ FaceWord + Layout)
(simple_E1_lLO_ie <- pairs(emm_E1_lLO_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_lLO_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_LO, 
                                         Label == label_LO[[1]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_lLO_tb, "pes")
```

```{r}
emm_E1_lLO_tb <- emmeans(anova_E1_lLO_tb, ~ FaceWord + Layout)
(simple_E1_lLO_tb <- pairs(emm_E1_lLO_tb, simple = "each", combine = TRUE, adjust = "none"))
```

##### Right LO
###### 4 * 2
```{r aov for univariate E1 LO right}
aov_E1_rLO <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E1_LO, Label == label_LO[[2]]))

aov_E1_rLO
```

```{r estimated marginal means for univairate E1 LO right}
emm_aov_E1_rLO <- emmeans(aov_E1_rLO, ~ FaceWord * Layout)

emm_aov_E1_rLO %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E1_rLO right}
contrast(emmeans(emm_aov_E1_rLO, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E1_rLO, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E1_rLO right}
contr_aov_E1_rLO <- contrast(emm_aov_E1_rLO, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E1, interaction = "pairwise") # , adjust = "none"
contr_aov_E1_rLO
```

###### 2 * 2
```{r}
anova_E1_rLO_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E1_LO, 
                                      Label == label_LO[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E1_rLO_ie, "pes")
```

```{r}
emm_E1_rLO_ie <- emmeans(anova_E1_rLO_ie, ~ FaceWord + Layout) 
(simple_E1_rLO_ie <- pairs(emm_E1_rLO_ie, simple = "each", combine = TRUE, adjust = "none"))
```


2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E1_rLO_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E1_LO, 
                                         Label == label_LO[[2]],
                                         Layout %in% c("top", "bottom")))
anova(anova_E1_rLO_tb, "pes")
```

```{r}
emm_E1_rLO_tb <- emmeans(anova_E1_rLO_tb, ~ FaceWord + Layout)
(simple_E1_rLO_tb <- pairs(emm_E1_rLO_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E1 (aov) LO, fig.asp = .8, fig.width = 8}

# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_aov_E1_lLO))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_LO <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E1_lLO), as.data.frame(emm_aov_E1_rLO)))


plot_uni_E1_LO <- plot_uni(desp_uni_E1_LO, contr_aov_E1_lLO, contr_aov_E1_rLO, "LO")

# ggsave('plot_uni_E1_LO.png', plot_uni_E1_LO, width = 10, height = 10)

plot_uni_E1_LO
```
<br/>
The above figure shows the neural respones (beta values) in LO for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: *, _p_ < .05

```{r plots for functional scans E1 (22 anova) LO ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lLO_ie))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_LO_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lLO_ie), as.data.frame(emm_E1_rLO_ie)))

plot_uni_E1_LO_ie <- plot_uni(desp_uni_E1_LO_ie, simple_E1_lLO_ie, simple_E1_rLO_ie, "LO", F)

# ggsave('plot_uni_E1_LO_ie.png', plot_uni_E1_LO_ie, width = 10, height = 5)
plot_uni_E1_LO_ie
```

```{r plots for functional scans E1 (22 anova) LO tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E1 <-nrow(as.data.frame(emm_E1_lLO_tb))
Hemisphere <- c(rep("left", nRow_E1), rep("right", nRow_E1))
desp_uni_E1_LO_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E1_lLO_tb), as.data.frame(emm_E1_rLO_tb)))

plot_uni_E1_LO_tb <- plot_uni(desp_uni_E1_LO_tb, simple_E1_lLO_tb, simple_E1_rLO_tb, "LO", F)

# ggsave('plot_uni_E1_LO_tb.png', plot_uni_E1_LO_tb, width = 10, height = 5)
plot_uni_E1_LO_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E1 LO}
# one-sample for results of decode E1 LO
one_decode_agg_E1_LO <- {
  df_decode_E1_LO %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E1)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E1_LO
```

#### Plot
```{r plots for functional scans decode E1 (anova) LO, fig.asp=2, fig.width = 7}

plot_decode_E1_LO <- plot_decode(one_decode_agg_E1_LO, "LO")

# ggsave('plot_decode_E1_LO.png', plot_decode_E1_LO, width = 6.5, height = 16)

plot_decode_E1_LO
```
<br/>
The above figure shows the decoding accuracy in LO for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: **, _p_ < .01; ***, _p_ <.001

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in LO E1}
# Similarity of top + bottom to intact vs. exchange in LO
one_simi_E1_LO <- {
  df_simi_E1_LO %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E1_LO
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in LO, fig.asp=1, fig.width = 8}

plot_simi_E1_LO <- plot_simi(one_simi_E1_LO, "LO")

# ggsave('plot_simi_E1_LO.png', plot_simi_E1_LO, width = 8, height = 10)

plot_simi_E1_LO
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in LO. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.


# Experiment 2: English and Chinese characters for Caucasian participants
## Load and clean data 

### Label (ROI) information
```{r label information E2, message=FALSE}
df_label_E2 <- read_csv(file.path("data", "faceword_E2_Label_HJ.csv")) %>% 
  mutate(roi = str_remove(Label, "roi."),
         roi = str_remove(roi, ".label")) %>% 
  mutate(Subject = str_replace(SubjCode, "\\_.*", ""))

# df_label %>% head()
```

#### Size of labels
```{r size (mm2) of labels for each subject E2}
df_label_E2 %>% 
  select(SubjCode, roi, Size) %>% 
  pivot_wider(names_from = roi, values_from = Size) %>% 
  arrange(SubjCode)
```
The above table displays the size (in mm2) of each label for each participant. (NA denotes that this label is not available for that particiapnt.)

#### Number of vertices for each label
```{r Number of vertices for each label E2}
df_label_E2 %>% 
  select(SubjCode, roi, NVtxs) %>% 
  pivot_wider(names_from = roi, values_from = NVtxs) %>% 
  arrange(SubjCode)
```
The above table displays the number of vertices for each label and each participant. (NA denotes that this label is not available for that particiapnt.)


#### Number of participants for each ROI
```{r Number of available labels for each ROI E2}
df_label_E2 %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 
```

#### Number of remaining participants
```{r Number of remaining participants E2}
df_nlabel_E2 <- df_label_E2 %>% 
  filter(Size > nVtx_size_min) %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 

df_nlabel_E2
```
The above table dispalys the number of participants included in the following analyses for each ROI. (VWFA is only found on the left hemisphere.)

### Data for univariate analyses
```{r load data file for univariate analysis E2, message=FALSE, include=showAll}
# load data file from functional scans for univerate analysis
df_uni_E2 <- read_csv(file.path("data", "faceword_E2_Uni_HJ.csv"))

head(df_uni_E2)
```

```{r clean the univariate data E2, include=showAll}
df_clean_uni_E2 <- {
  df_uni_E2 %>% 
    filter(Response != "NaN") %>% 
    separate(Condition, c("FaceWord", "Layout"), "_") %>% # separate the conditions into two IVs
    mutate(Layout_ = factor(Layout, levels = layout_order), # convert the two IVs to factors
           Hemisphere = if_else(grepl("lh", Label), "left", if_else(grepl("rh", Label), "right", "NA")),
           Layout = fct_recode(Layout_, partA = "top", partB = "bottom")) %>% # rename top and bottom as part1 and part2
    select(Hemisphere, Label, SessCode, FaceWord, Layout, Response) %>% 
    mutate(Subject = str_replace(SessCode, "\\_.*", "")) %>% 
    left_join(df_label_E2, by = c("Label", "Subject")) %>% 
    filter(Size > nVtx_size_min)
}

head(df_clean_uni_E2)
```

### Data of decoding
```{r assign filenames E2, include=showAll}
pair_order_E2 <- c("English_intact-Chinese_intact",
                   "English_intact-English_exchange",
                   "English_partA-English_partB", # English_top-English_bottom
                   "Chinese_intact-Chinese_exchange",
                   "Chinese_partA-Chinese_partB") # Chinese_top-Chinese_bottom

```

```{r load data file from cosmoMVPA E2, message=FALSE, include=showAll}
df_decode_E2 <- read_csv(file.path("data", "faceword_E2_Decode_noz.csv"))

head(df_decode_E2)
```

```{r clean the cosmoMVPA data E2, include=showAll}
df_clean_decode_E2 <- df_decode_E2 %>% 
  select(Label, SessCode, ClassifyPair, ACC) %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), "left", 
                              if_else(grepl("rh", Label), "right", "NA")),
         Subject = str_remove(SessCode, "\\_.*"),
         ClassifyPair = fct_recode(ClassifyPair, 
                                   `Chinese_partA-Chinese_partB` = "Chinese_top-Chinese_bottom",
                                   `English_partA-English_partB` = "English_top-English_bottom"),
         ClassifyPair = factor(ClassifyPair, levels = pair_order_E2)) %>% 
  left_join(df_label_E2, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_decode_acc_E2 <- df_clean_decode_E2 %>% 
  group_by(Hemisphere, Label, SessCode, ClassifyPair) %>% # divide the data into groups by these columns 
  summarize(Accuracy = mean(ACC), Count = n()) %>% 
  ungroup()

df_decode_acc_E2
```

### Data for the Similarity of top + bottom
```{r assign filenames simi E2, include=showAll}
simi_order_E2 <- c("English_partA0.25-English_partB0.75",
                   "English_partA0.50-English_partB0.50",
                   "English_partA0.75-English_partB0.25",
                   "Chinese_partA0.25-Chinese_partB0.75",
                   "Chinese_partA0.50-Chinese_partB0.50",
                   "Chinese_partA0.75-Chinese_partB0.25") 

```


```{r Data for the Similarity of top + bottom E2, message=FALSE, include=showAll}
df_simi_E2 <- read_csv(file.path("data", "faceword_E2_Similarity_noz.csv"))

head(df_simi_E2)
```

```{r clean the similarity data E2, include=showAll}

df_clean_simi_E2 <- df_simi_E2 %>% 
  mutate(asExchange = if_else(grepl("exchange", PredictCond), 1, 0),  # binary prediction
         pExchange = Probability_2,  # probability prediction
         Subject = str_remove(SessCode, "\\_.*"),
         Combination = gsub("top", "partA", Combination),
         Combination = gsub("bottom", "partB", Combination),
         Combination = factor(Combination, levels = simi_order_E2)) %>% 
  left_join(df_label_E2, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_rate_simi_E2 <- df_clean_simi_E2 %>% 
  group_by(SessCode, Label, ClassPair_1, Combination) %>% 
  summarize(binaryAsExchange = mean(asExchange),
            pAsExchange = mean(pExchange),
            RateAsExchange = pAsExchange) %>%  # use the probability instead of the categorical prediction
  ungroup() %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), 'left', if_else(grepl("rh", Label), "right", "NA")))

head(df_rate_simi_E2)

```

## Label:FFA1
```{r only keep data for FFA1 E2}
# only keep data for these two labels
df_uni_E2_FFA1 <- filter(df_clean_uni_E2, Label %in% label_FFA1)
df_decode_E2_FFA1 <- filter(df_decode_acc_E2, Label %in% label_FFA1)
df_simi_E2_FFA1 <- filter(df_rate_simi_E2, Label %in% label_FFA1)

df_uni_E2_FFA1 %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left FFA1
###### 4 * 2
```{r anova for univariate E2 FFA1 left}
anova_E2_lFFA1 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA1, Label == label_FFA1[[1]]))

anova_E2_lFFA1
```

```{r estimated marginal means for univairate E2 lFFA1}
emm_aov_E2_lFFA1 <- emmeans(anova_E2_lFFA1, ~ FaceWord * Layout)

emm_aov_E2_lFFA1 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_lFFA1}
contrast(emmeans(emm_aov_E2_lFFA1, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_lFFA1, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_lFFA1}
contr_aov_E2_lFFA1 <- contrast(emm_aov_E2_lFFA1, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_lFFA1
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E2_lFFA1_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA1, 
                                         Label == label_FFA1[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E2_lFFA1_ie, "pes")
```

```{r}
emm_E2_lFFA1_ie <- emmeans(anova_E2_lFFA1_ie, ~ FaceWord + Layout)
(simple_E2_lFFA1_ie <- pairs(emm_E2_lFFA1_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_lFFA1_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA1, 
                                         Label == label_FFA1[[1]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_lFFA1_tb, "pes")
```

```{r}
emm_E2_lFFA1_tb <- emmeans(anova_E2_lFFA1_tb, ~ FaceWord + Layout)
(simple_E2_lFFA1_tb <- pairs(emm_E2_lFFA1_tb, simple = "each", combine = TRUE, adjust = "none"))
```

##### Right FFA1
###### 4 * 2
```{r anova for univariate E2 FFA1 right}
anova_E2_rFFA1 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA1, Label == label_FFA1[[2]]))

anova_E2_rFFA1
```

```{r estimated marginal means for univairate E2 FFA1 right}
emm_aov_E2_rFFA1 <- emmeans(anova_E2_rFFA1, ~ FaceWord * Layout)

emm_aov_E2_rFFA1 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_rFFA1 right}
contrast(emmeans(emm_aov_E2_rFFA1, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_rFFA1, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_rFFA1 right}
contr_aov_E2_rFFA1 <- contrast(emm_aov_E2_rFFA1, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_rFFA1
```

###### 2 * 2
```{r}
anova_E2_rFFA1_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA1, 
                                      Label == label_FFA1[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E2_rFFA1_ie, "pes")
```

```{r}
emm_E2_rFFA1_ie <- emmeans(anova_E2_rFFA1_ie, ~ FaceWord + Layout) 
(simple_E2_rFFA1_ie <- pairs(emm_E2_rFFA1_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_rFFA1_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA1, 
                                         Label == label_FFA1[[2]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_rFFA1_tb, "pes")
```

```{r}
emm_E2_rFFA1_tb <- emmeans(anova_E2_rFFA1_tb, ~ FaceWord + Layout)
(simple_E2_rFFA1_tb <- pairs(emm_E2_rFFA1_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E2 (anova) FFA1, fig.asp = .8, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_aov_E2_lFFA1))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA1 <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E2_lFFA1), as.data.frame(emm_aov_E2_rFFA1)))

plot_uni_E2_FFA1 <- plot_uni(desp_uni_E2_FFA1, contr_aov_E2_lFFA1, contr_aov_E2_rFFA1, "FFA1")

# ggsave('plot_uni_E2_FFA1.png', plot_uni_E2_FFA1, width = 10, height = 10)

plot_uni_E2_FFA1
```
<br/>
The above figure shows the neural respones (beta values) in FFA1 for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals. 
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

```{r plots for functional scans E2 (22 anova) FFA1 ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lFFA1_ie))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA1_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lFFA1_ie), as.data.frame(emm_E2_rFFA1_ie)))

plot_uni_E2_FFA1_ie <- plot_uni(desp_uni_E2_FFA1_ie, simple_E2_lFFA1_ie, simple_E2_rFFA1_ie, "FFA1", F)

# ggsave('plot_uni_E2_FFA1_ie.png', plot_uni_E2_FFA1_ie, width = 10, height = 5)
plot_uni_E2_FFA1_ie
```

```{r plots for functional scans E2 (22 anova) FFA1 tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lFFA1_tb))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA1_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lFFA1_tb), as.data.frame(emm_E2_rFFA1_tb)))

plot_uni_E2_FFA1_tb <- plot_uni(desp_uni_E2_FFA1_tb, simple_E2_lFFA1_tb, simple_E2_rFFA1_tb, "FFA1", F, T)

# ggsave('plot_uni_E2_FFA1_tb.png', plot_uni_E2_FFA1_tb, width = 10, height = 5)
plot_uni_E2_FFA1_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E2 FFA1}
# one-sample for results of decode E2 FFA1
one_decode_agg_E2_FFA1 <- {
  df_decode_E2_FFA1 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E2)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E2_FFA1
```

#### Plot
```{r plots for functional scans decode E2 (anova) FFA1, fig.asp=2, fig.width = 7}

plot_decode_E2_FFA1 <- plot_decode(one_decode_agg_E2_FFA1, "FFA1")

# ggsave('plot_decode_E2_FFA1.png', plot_decode_E2_FFA1, width = 6.5, height = 16)
plot_decode_E2_FFA1
```
<br/>
The above figure shows the decoding accuracy in FFA1 for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in FFA1 E2}

one_simi_E2_FFA1 <- {
  df_simi_E2_FFA1 %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E2_FFA1
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in FFA1 E2, fig.asp=1, fig.width = 8}
plot_simi_E2_FFA1 <- plot_simi(one_simi_E2_FFA1, "FFA1")
# ggsave('plot_simi_E2_FFA1.png', plot_simi_E2_FFA1, width = 8, height = 10)
plot_simi_E2_FFA1
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in FFA1. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.

## Label:FFA2
```{r only keep data for FFA2 E2}
# only keep data for these two labels
df_uni_E2_FFA2 <- filter(df_clean_uni_E2, Label %in% label_FFA2)
df_decode_E2_FFA2 <- filter(df_decode_acc_E2, Label %in% label_FFA2)
df_simi_E2_FFA2 <- filter(df_rate_simi_E2, Label %in% label_FFA2)

df_uni_E2_FFA2 %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left FFA2
###### 4 * 2
```{r anova for univariate E2 FFA2 left}
anova_E2_lFFA2 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA2, Label == label_FFA2[[1]]))

anova_E2_lFFA2
```

```{r estimated marginal means for univairate E2 lFFA2}
emm_aov_E2_lFFA2 <- emmeans(anova_E2_lFFA2, ~ FaceWord * Layout)

emm_aov_E2_lFFA2 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_lFFA2}
contrast(emmeans(emm_aov_E2_lFFA2, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_lFFA2, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_lFFA2}
contr_aov_E2_lFFA2 <- contrast(emm_aov_E2_lFFA2, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_lFFA2
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E2_lFFA2_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA2, 
                                         Label == label_FFA2[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E2_lFFA2_ie, "pes")
```

```{r}
emm_E2_lFFA2_ie <- emmeans(anova_E2_lFFA2_ie, ~ FaceWord + Layout)
(simple_E2_lFFA2_ie <- pairs(emm_E2_lFFA2_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_lFFA2_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA2, 
                                         Label == label_FFA2[[1]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_lFFA2_tb, "pes")
```

```{r}
emm_E2_lFFA2_tb <- emmeans(anova_E2_lFFA2_tb, ~ FaceWord + Layout)
(simple_E2_lFFA2_tb <- pairs(emm_E2_lFFA2_tb, simple = "each", combine = TRUE, adjust = "none"))
```


##### Right FFA2
###### 4 * 2
```{r anova for univariate E2 FFA2 right}
anova_E2_rFFA2 <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA2, Label == label_FFA2[[2]]))

anova_E2_rFFA2
```

```{r estimated marginal means for univairate E2 FFA2 right}
emm_aov_E2_rFFA2 <- emmeans(anova_E2_rFFA2, ~ FaceWord * Layout)

emm_aov_E2_rFFA2 %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_rFFA2 right}
contrast(emmeans(emm_aov_E2_rFFA2, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_rFFA2, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_rFFA2 right}
contr_aov_E2_rFFA2 <- contrast(emm_aov_E2_rFFA2, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_anova_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_rFFA2
```

###### 2 * 2
```{r}
anova_E2_rFFA2_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_FFA2, 
                                      Label == label_FFA2[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E2_rFFA2_ie, "pes")
```

```{r}
emm_E2_rFFA2_ie <- emmeans(anova_E2_rFFA2_ie, ~ FaceWord + Layout) 
(simple_E2_rFFA2_ie <- pairs(emm_E2_rFFA2_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_rFFA2_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_FFA2, 
                                         Label == label_FFA2[[2]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_rFFA2_tb, "pes")
```

```{r}
emm_E2_rFFA2_tb <- emmeans(anova_E2_rFFA2_tb, ~ FaceWord + Layout)
(simple_E2_rFFA2_tb <- pairs(emm_E2_rFFA2_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E2 (anova) FFA2, fig.asp = .8, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_aov_E2_lFFA2))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA2 <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E2_lFFA2), as.data.frame(emm_aov_E2_rFFA2)))

plot_uni_E2_FFA2 <- plot_uni(desp_uni_E2_FFA2, contr_aov_E2_lFFA2, contr_aov_E2_rFFA2, "FFA2")

# ggsave('plot_uni_E2_FFA2.png', plot_uni_E2_FFA2, width = 10, height = 10)

plot_uni_E2_FFA2
```
<br/>
The above figure shows the neural respones (beta values) in FFA2 for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

```{r plots for functional scans E2 (22 anova) FFA2 ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lFFA2_ie))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA2_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lFFA2_ie), as.data.frame(emm_E2_rFFA2_ie)))

plot_uni_E2_FFA2_ie <- plot_uni(desp_uni_E2_FFA2_ie, simple_E2_lFFA2_ie, simple_E2_rFFA2_ie, "FFA2", F)

# ggsave('plot_uni_E2_FFA2_ie.png', plot_uni_E2_FFA2_ie, width = 10, height = 5)
plot_uni_E2_FFA2_ie
```

```{r plots for functional scans E2 (22 anova) FFA2 tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lFFA2_tb))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_FFA2_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lFFA2_tb), as.data.frame(emm_E2_rFFA2_tb)))

plot_uni_E2_FFA2_tb <- plot_uni(desp_uni_E2_FFA2_tb, simple_E2_lFFA2_tb, simple_E2_rFFA2_tb, "FFA2", F, T)

# ggsave('plot_uni_E2_FFA2_tb.png', plot_uni_E2_FFA2_tb, width = 10, height = 5)
plot_uni_E2_FFA2_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E2 FFA2}
# one-sample for results of decode E2 FFA2
one_decode_agg_E2_FFA2 <- {
  df_decode_E2_FFA2 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E2)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E2_FFA2
```

#### Plot
```{r plots for functional scans decode E2 (anova) FFA2, fig.asp=2, fig.width = 7}
plot_decode_E2_FFA2 <- plot_decode(one_decode_agg_E2_FFA2, "FFA2")

# ggsave('plot_decode_E2_FFA2.png', plot_decode_E2_FFA2, width = 6.5, height = 16)
plot_decode_E2_FFA2
```
<br/>
The above figure shows the decoding accuracy in FFA2 for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: "<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>"

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in FFA2 E2}
# Similarity of top + bottom to intact vs. exchange in FFA
one_simi_E2_FFA2 <- {
  df_simi_E2_FFA2 %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E2_FFA2
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in FFA2 E2, fig.asp=1, fig.width = 8}

plot_simi_E2_FFA2 <- plot_simi(one_simi_E2_FFA2, "FFA2")
# ggsave('plot_simi_E2_FFA2.png', plot_simi_E2_FFA2, width = 8, height = 10)

plot_simi_E2_FFA2
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in FFA2. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.


## Label: left Visual Word Form Area (VWFA)
```{r only keep data for VWFA E2}
# only keep data for these two labels
df_uni_E2_VWFA <- filter(df_clean_uni_E2, Label %in% label_VWFA)
df_decode_E2_VWFA <- filter(df_decode_acc_E2, Label %in% label_VWFA)
df_simi_E2_VWFA <- filter(df_rate_simi_E2, Label %in% label_VWFA)

# subjects used for each hemisphere
# unique(as.character((df_univar_agg_E2_VWFA %>% filter(Label == label_VWFA_E2))$SubjCode))

df_uni_E2_VWFA %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
###### 4 * 2
```{r anova for univariate E2 VWFA left}
anova_E2_VWFA <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E2_VWFA, Label == label_VWFA))

anova_E2_VWFA
```

```{r estimated marginal means for univairate E2 VWFA}
emm_aov_E2_VWFA <- emmeans(anova_E2_VWFA, ~ FaceWord * Layout)

emm_aov_E2_VWFA %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_VWFA}
contrast(emmeans(emm_aov_E2_VWFA, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_VWFA, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_VWFA}
contr_aov_E2_VWFA <- contrast(emm_aov_E2_VWFA, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_VWFA
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E2_VWFA_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_VWFA, 
                                         Label == label_VWFA[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E2_VWFA_ie, "pes")
```

```{r}
emm_E2_VWFA_ie <- emmeans(anova_E2_VWFA_ie, ~ FaceWord + Layout)
(simple_E2_VWFA_ie <- pairs(emm_E2_VWFA_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_VWFA_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_VWFA, 
                                         Label == label_VWFA[[1]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_VWFA_tb, "pes")
```

```{r}
emm_E2_VWFA_tb <- emmeans(anova_E2_VWFA_tb, ~ FaceWord + Layout)
(simple_E2_VWFA_tb <- pairs(emm_E2_VWFA_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E2 (anova) VWFA, fig.asp = 1, fig.width = 6}


nRow_E2 <-nrow(as.data.frame(emm_aov_E2_VWFA))
Hemisphere <- c(rep("left", nRow_E2))
desp_uni_E2_VWFA <- cbind(Hemisphere, as.data.frame(emm_aov_E2_VWFA))


plot_uni_E2_VWFA <- plot_uni_vwfa(desp_uni_E2_VWFA, contr_aov_E2_VWFA, "VWFA")

# ggsave('plot_uni_E2_VWFA.png', plot_uni_E2_VWFA, width = 5.5, height = 10)

plot_uni_E2_VWFA
```
<br/>
The above figure shows the neural respones (beta values) in VWFA for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: *, _p_ < .05

```{r plots for functional scans E2 (anova) VWFA ie, fig.asp = .5, fig.width = 6}
nRow_E2 <-nrow(as.data.frame(emm_E2_VWFA_ie))
Hemisphere <- c(rep("left", nRow_E2))
desp_uni_E2_VWFA_ie <- cbind(Hemisphere, as.data.frame(emm_E2_VWFA_ie))

plot_uni_E2_VWFA_ie <- plot_uni_vwfa(desp_uni_E2_VWFA_ie, simple_E2_VWFA_tb, "VWFA", FALSE)

# ggsave('plot_uni_E2_VWFA_ie.png', plot_uni_E2_VWFA_ie, width = 5.5, height = 10)
plot_uni_E2_VWFA_ie
```

```{r plots for functional scans E2 (anova) VWFA tb, fig.asp = .5, fig.width = 6}
nRow_E2 <-nrow(as.data.frame(emm_E2_VWFA_tb))
Hemisphere <- c(rep("left", nRow_E2))
desp_uni_E2_VWFA_tb <- cbind(Hemisphere, as.data.frame(emm_E2_VWFA_tb))

plot_uni_E2_VWFA_tb <- plot_uni_vwfa(desp_uni_E2_VWFA_tb, simple_E2_VWFA_tb, "VWFA", FALSE, T)

# ggsave('plot_uni_E2_VWFA_tb.png', plot_uni_E2_VWFA_tb, width = 5.5, height = 10)
plot_uni_E2_VWFA_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E2 VWFA}
# one-sample for results of decode E2 VWFA
one_decode_agg_E2_VWFA <- {
  df_decode_E2_VWFA %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E2)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E2_VWFA

```

#### Plot
```{r plots for functional scans decode E2 (anova) VWFA, fig.asp=4, fig.width = 4}
plot_decode_E2_VWFA <- plot_decode_vwfa(one_decode_agg_E2_VWFA, "VWFA")
# ggsave('plot_decode_E2_VWFA.png', plot_decode_E2_VWFA, width = 4, height = 16)

plot_decode_E2_VWFA
```
<br/>
The above figure shows the decoding accuracy in VWFA for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: ***, _p_ <.001

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in VWFA E2}
# Similarity of top + bottom to intact vs. exchange in VWFA
one_simi_E2_VWFA <- {
  df_simi_E2_VWFA %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E2_VWFA
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in VWFA E2, fig.asp=2, fig.width = 4}

plot_simi_E2_VWFA <- plot_simi_vwfa(one_simi_E2_VWFA, "VWFA")

# ggsave('plot_simi_E2_VWFA.png', plot_simi_E2_VWFA, width = 4.25, height = 10)
plot_simi_E2_VWFA
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in VWFA. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.

## Label:Lateral Occipital Cortex
```{r only keep data for LO E2}
# only keep data for these two labels
df_uni_E2_LO <- filter(df_clean_uni_E2, Label %in% label_LO)
df_decode_E2_LO <- filter(df_decode_acc_E2, Label %in% label_LO)
df_simi_E2_LO <- filter(df_rate_simi_E2, Label %in% label_LO)

df_uni_E2_LO %>% 
  select(Hemisphere, Label, SessCode) %>% 
  distinct() %>% 
  group_by(Hemisphere, Label) %>% 
  summarize(Count = n()) 
```

### Univariate analyses
#### rm-ANOVA 
##### Left LO
###### 4 * 2
```{r anova for univariate E2 LO left}
anova_E2_lLO <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E2_LO, Label == label_LO[[1]]))

anova_E2_lLO
```

```{r estimated marginal means for univairate E2 lLO}
emm_aov_E2_lLO <- emmeans(anova_E2_lLO, ~ FaceWord * Layout)

emm_aov_E2_lLO %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_lLO}
contrast(emmeans(emm_aov_E2_lLO, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_lLO, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_lLO}
contr_aov_E2_lLO <- contrast(emm_aov_E2_lLO, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_lLO
```

###### 2 * 2
2(face vs. word)$\times$2(intact vs. exchange) ANOVA
```{r}
anova_E2_lLO_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_LO, 
                                         Label == label_LO[[1]],
                                         Layout %in% c("intact", "exchange")))
anova(anova_E2_lLO_ie, "pes")
```

```{r}
emm_E2_lLO_ie <- emmeans(anova_E2_lLO_ie, ~ FaceWord + Layout)
(simple_E2_lLO_ie <- pairs(emm_E2_lLO_ie, simple = "each", combine = TRUE, adjust = "none"))
```

2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_lLO_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_LO, 
                                         Label == label_LO[[1]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_lLO_tb, "pes")
```

```{r}
emm_E2_lLO_tb <- emmeans(anova_E2_lLO_tb, ~ FaceWord + Layout)
(simple_E2_lLO_tb <- pairs(emm_E2_lLO_tb, simple = "each", combine = TRUE, adjust = "none"))
```

##### Right LO
###### 4 * 2
```{r aov for univariate E2 LO right}
aov_E2_rLO <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                       data = filter(df_uni_E2_LO, Label == label_LO[[2]]))

aov_E2_rLO
```

```{r estimated marginal means for univairate E2 LO right}
emm_aov_E2_rLO <- emmeans(aov_E2_rLO, ~ FaceWord * Layout)

emm_aov_E2_rLO %>% 
  as.data.frame() %>% 
  arrange(FaceWord)
```
<br>
Posthoc analysis for the main effects:
```{r post-hoc for emm_aov_E2_rLO right}
contrast(emmeans(emm_aov_E2_rLO, ~ FaceWord), "pairwise")

contrast(emmeans(emm_aov_E2_rLO, ~ Layout), "pairwise") # , adjust = "none"
```
<br>
Results of simple effect analysis (uncorrected):
```{r simple effect analysis for emm_aov_E2_rLO right}
contr_aov_E2_rLO <- contrast(emm_aov_E2_rLO, "pairwise", simple = "each", combine = TRUE, adjust = "none")
# contrast(emm_uni_aov_E2, interaction = "pairwise") # , adjust = "none"
contr_aov_E2_rLO
```

###### 2 * 2
```{r}
anova_E2_rLO_ie <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                        data = filter(df_uni_E2_LO, 
                                      Label == label_LO[[2]],
                                      Layout %in% c("intact", "exchange")))
anova(anova_E2_rLO_ie, "pes")
```

```{r}
emm_E2_rLO_ie <- emmeans(anova_E2_rLO_ie, ~ FaceWord + Layout) 
(simple_E2_rLO_ie <- pairs(emm_E2_rLO_ie, simple = "each", combine = TRUE, adjust = "none"))
```


2(face vs. word)$\times$2(top vs. bottom) ANOVA
```{r}
anova_E2_rLO_tb <- aov_4(Response ~ FaceWord * Layout + (FaceWord * Layout | SubjCode), 
                           data = filter(df_uni_E2_LO, 
                                         Label == label_LO[[2]],
                                         Layout %in% c("partA", "partB")))
anova(anova_E2_rLO_tb, "pes")
```

```{r}
emm_E2_rLO_tb <- emmeans(anova_E2_rLO_tb, ~ FaceWord + Layout)
(simple_E2_rLO_tb <- pairs(emm_E2_rLO_tb, simple = "each", combine = TRUE, adjust = "none"))
```

#### Plot
```{r plots for functional scans E2 (aov) LO, fig.asp = .8, fig.width = 8}

# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_aov_E2_lLO))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_LO <- cbind(Hemisphere, rbind(as.data.frame(emm_aov_E2_lLO), as.data.frame(emm_aov_E2_rLO)))

plot_uni_E2_LO <- plot_uni(desp_uni_E2_LO, contr_aov_E2_lLO, contr_aov_E2_rLO, "LO")

# ggsave('plot_uni_E2_LO.png', plot_uni_E2_LO, width = 10, height = 10)

plot_uni_E2_LO
```
<br/>
The above figure shows the neural respones (beta values) in LO for each condition. The numbers are the p-values for the tests of differences between intact vs. exchange in that condition. Error bars represent 95% confidence intervals.
Note: *, _p_ < .05

```{r plots for functional scans E2 (22 anova) LO ie, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lLO_ie))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_LO_ie <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lLO_ie), as.data.frame(emm_E2_rLO_ie)))

plot_uni_E2_LO_ie <- plot_uni(desp_uni_E2_LO_ie, simple_E2_lLO_ie, simple_E2_rLO_ie, "LO", F)

# ggsave('plot_uni_E2_LO_ie.png', plot_uni_E2_LO_ie, width = 10, height = 5)
plot_uni_E2_LO_ie
```

```{r plots for functional scans E2 (22 anova) LO tb, fig.asp =.4, fig.width = 8}
# add the column of Hemisphere
nRow_E2 <-nrow(as.data.frame(emm_E2_lLO_tb))
Hemisphere <- c(rep("left", nRow_E2), rep("right", nRow_E2))
desp_uni_E2_LO_tb <- cbind(Hemisphere, rbind(as.data.frame(emm_E2_lLO_tb), as.data.frame(emm_E2_rLO_tb)))

plot_uni_E2_LO_tb <- plot_uni(desp_uni_E2_LO_tb, simple_E2_lLO_tb, simple_E2_rLO_tb, "LO", F, T)

# ggsave('plot_uni_E2_LO_tb.png', plot_uni_E2_LO_tb, width = 10, height = 5)
plot_uni_E2_LO_tb
```

### Decoding
#### One-sample t-test
```{r one-sample for results of decode E2 LO}
# one-sample for results of decode E2 LO
one_decode_agg_E2_LO <- {
  df_decode_E2_LO %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E2)) %>% 
    group_by(Hemisphere, ClassifyPair) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E2_LO
```

#### Plot
```{r plots for functional scans decode E2 (anova) LO, fig.asp=2, fig.width = 7}

plot_decode_E2_LO <- plot_decode(one_decode_agg_E2_LO, "LO")

# ggsave('plot_decode_E2_LO.png', plot_decode_E2_LO, width = 6.5, height = 16)

plot_decode_E2_LO
```
<br/>
The above figure shows the decoding accuracy in LO for each pair. The numbers are the p-values for the one-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.
Note: **, _p_ < .01; ***, _p_ <.001

### Similarity of top + bottom to intact vs. exchange
#### One-sample t-test
```{r Similarity of top + bottom to intact vs. exchange in LO E2}
# Similarity of top + bottom to intact vs. exchange in LO
one_simi_E2_LO <- {
  df_simi_E2_LO %>% 
    group_by(Hemisphere, Combination) %>% 
    summarize(mean = t.test(RateAsExchange, mu = 0.5)[[5]],
              SD = t.test(RateAsExchange, mu = 0.5)[[7]],
              t = t.test(RateAsExchange, mu = 0.5)[[1]],
              df = t.test(RateAsExchange, mu = 0.5)[[2]],
              p = round(t.test(RateAsExchange, mu = 0.5)[[3]], 5),
              lower.CL = t.test(RateAsExchange, mu = 0.5)[[4]][1],
              upper.CL = t.test(RateAsExchange, mu = 0.5)[[4]][2],
              nullValue = t.test(RateAsExchange, mu = 0.5)[[6]],
              alternative = t.test(RateAsExchange, mu = 0.5)[[8]]
    )
}

one_simi_E2_LO
```

#### Plot
```{r plot Similarity of top+bottom to intact vs. exchange in LO E2, fig.asp=1, fig.width = 8}

plot_simi_E2_LO <- plot_simi(one_simi_E2_LO, "LO")

# ggsave('plot_simi_E2_LO.png', plot_simi_E2_LO, width = 8, height = 10)

plot_simi_E2_LO
```
<br/>
The above figure shows the probability of top+bottom being decoded as exchange conditions in LO. Patterns of top and bottom were combined with different weights, i.e., "face_top0.25-face_bottom0.75" denotes the linear combinations of face_top and face_bottom with the weights of 0.25/0.75. The numbers are the p-values for the two-tail one-sample t-tests against the chance level (0.5) in that condition. Error bars represent 95% confidence intervals.

# Decoding in LO with different area sizes

Labels for LO were defined with the maximum area of 100, 150, 200 and 300 mm^2, respecitvely. 

## Experiment 1

### LO Label (ROI) information

```{r label information E1 LO, message=FALSE}
df_label_LO_E1 <- read_csv(file.path("data", "faceword_E1_Label_LO_HJ.csv")) %>% 
  mutate(roi = str_remove(Label, "roi."),
         roi = str_remove(roi, ".label")) %>% 
  mutate(Subject = str_replace(SubjCode, "\\_.*", ""))

# df_label %>% head()
```

#### Size of labels
```{r size (mm2) of labels for each subject E1 LO}
df_label_LO_E1 %>% 
  select(SubjCode, roi, Size) %>% 
  pivot_wider(names_from = roi, values_from = Size) %>% 
  arrange(SubjCode)
```
The above table displays the size (in mm2) of each label for each participant. (NA denotes that this label is not available for that particiapnt.)

#### Number of vertices for each label
```{r Number of vertices for each label E1 LO}
df_label_LO_E1 %>% 
  select(SubjCode, roi, NVtxs) %>% 
  pivot_wider(names_from = roi, values_from = NVtxs) %>% 
  arrange(SubjCode)
```
The above table displays the number of vertices for each label and each participant. (NA denotes that this label is not available for that particiapnt.)


#### Number of participants for each ROI
```{r Number of available labels for each ROI E1 LO}
df_label_LO_E1 %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 
```

#### Number of remaining participants
```{r Number of remaining participants E1 LO}
df_nlabel_LO_E1 <- df_label_LO_E1 %>% 
  filter(Size > nVtx_size_min) %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 

df_nlabel_LO_E1
```
The above table dispalys the number of participants included in the following analyses for each ROI. (VWFA is only found on the left hemisphere.)

### Decoding
```{r}
# load decoding results in LO
df_LO_area_E1 <- read_csv(file.path("data", "faceword_E1_Decode_LO_noz.csv")) %>% 
  select(Label, SessCode, ClassifyPair, ACC) %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), "left", 
                              if_else(grepl("rh", Label), "right", "NA")),
         Subject = str_remove(SessCode, "\\_.*")) %>% 
  left_join(df_label_LO_E1, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_decode_LO_acc_E1 <- df_LO_area_E1 %>% 
  group_by(Hemisphere, Label, SessCode, ClassifyPair) %>% # divide the data into groups by these columns 
  summarize(Accuracy = mean(ACC), Count = n()) %>% 
  ungroup()

df_decode_LO_acc_E1
```

#### One-sample t-test
```{r one-sample for results of decode E1 LO area}
# one-sample for results of decode E1 LO
one_decode_agg_E1_LO_area <- {
  df_decode_LO_acc_E1 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E1)) %>% 
    group_by(Hemisphere, ClassifyPair, Label) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E1_LO_area
```


## Experiment 2

### LO Label (ROI) information

```{r label information E2 LO, message=FALSE}
df_label_LO_E2 <- read_csv(file.path("data", "faceword_E2_Label_LO_HJ.csv")) %>% 
  mutate(roi = str_remove(Label, "roi."),
         roi = str_remove(roi, ".label")) %>% 
  mutate(Subject = str_replace(SubjCode, "\\_.*", ""))
# df_label %>% head()
```

#### Size of labels
```{r size (mm2) of labels for each subject E2 LO}
df_label_LO_E2 %>% 
  select(SubjCode, roi, Size) %>% 
  pivot_wider(names_from = roi, values_from = Size) %>% 
  arrange(SubjCode)
```
The above table displays the size (in mm2) of each label for each participant. (NA denotes that this label is not available for that particiapnt.)

#### Number of vertices for each label
```{r Number of vertices for each label E2 LO}
df_label_LO_E2 %>% 
  select(SubjCode, roi, NVtxs) %>% 
  pivot_wider(names_from = roi, values_from = NVtxs) %>% 
  arrange(SubjCode)
```
The above table displays the number of vertices for each label and each participant. (NA denotes that this label is not available for that particiapnt.)


#### Number of participants for each ROI
```{r Number of available labels for each ROI E2 LO}
df_label_LO_E2 %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 
```

#### Number of remaining participants
```{r Number of remaining participants E2 LO}
df_nlabel_LO_E2 <- df_label_LO_E2 %>% 
  filter(Size > nVtx_size_min) %>% 
  group_by(Label, roi) %>% 
  summarize(Count = n(),
            meanSize = mean(Size),
            meanNVtx = mean(NVtxs)) 

df_nlabel_LO_E2
```
The above table dispalys the number of participants included in the following analyses for each ROI. (VWFA is only found on the left hemisphere.)

### Decoding
```{r}
# load decoding results in LO
df_LO_area_E2 <- read_csv(file.path("data", "faceword_E2_Decode_LO_noz.csv")) %>% 
  select(Label, SessCode, ClassifyPair, ACC) %>% 
  mutate(Hemisphere = if_else(grepl("lh", Label), "left", 
                              if_else(grepl("rh", Label), "right", "NA")),
         Subject = str_remove(SessCode, "\\_.*"),
         ClassifyPair = fct_recode(ClassifyPair, 
                                   `Chinese_partA-Chinese_partB` = "Chinese_top-Chinese_bottom",
                                   `English_partA-English_partB` = "English_top-English_bottom"),
         ClassifyPair = factor(ClassifyPair, levels = pair_order_E2)) %>% 
  left_join(df_label_LO_E2, by = c("Label", "Subject")) %>% 
  filter(Size > nVtx_size_min)

df_decode_LO_acc_E2 <- df_LO_area_E2 %>% 
  group_by(Hemisphere, Label, SessCode, ClassifyPair) %>% # divide the data into groups by these columns 
  summarize(Accuracy = mean(ACC), Count = n()) %>% 
  ungroup()

df_decode_LO_acc_E2
```

#### One-sample t-test
```{r one-sample for results of decode E2 LO area}
# one-sample for results of decode E2 LO
one_decode_agg_E2_LO_area <- {
  df_decode_LO_acc_E2 %>% 
    mutate(ClassifyPair = fct_relevel(ClassifyPair, pair_order_E2)) %>% 
    group_by(Hemisphere, ClassifyPair, Label) %>% 
    summarize(mean = t.test(Accuracy, mu = 0.5, alternative = "greater")[[5]],
              SD = t.test(Accuracy, mu = 0.5, alternative = "greater")[[7]],
              t = t.test(Accuracy, mu = 0.5, alternative = "greater")[[1]],
              df = t.test(Accuracy, mu = 0.5, alternative = "greater")[[2]],
              p = round(t.test(Accuracy, mu = 0.5, alternative = "greater")[[3]], 5),
              lower.CL = t.test(Accuracy, mu = 0.5, alternative = "greater")[[4]][1],
              upper.CL = mean * 2 - lower.CL, # t.test(Accuracy, mu = 0.5, alternative = "two.sided")[[4]][2],
              nullValue = t.test(Accuracy, mu = 0.5, alternative = "greater")[[6]],
              alternative = t.test(Accuracy, mu = 0.5, alternative = "greater")[[8]]
    )
}

one_decode_agg_E2_LO_area
```

## Plot
```{r}
df_decode_LO_area <- rbind(mutate(one_decode_agg_E1_LO_area, Exp = "E1"),
                           mutate(one_decode_agg_E2_LO_area, Exp = "E2")) %>% 
  separate(ClassifyPair, c("Stimuli1", "Layout1", "Stimuli2", "Layout2")) %>% 
  filter(!(Label %in% c("roi.lh.o-vs-scr.label", "roi.rh.o-vs-scr.label"))) %>% 
  mutate(Stimuli1 = if_else(Stimuli1 %in% c("face", "word"), paste0(Stimuli1, "s"), Stimuli1),
         Stimuli2 = if_else(Stimuli2 %in% c("face", "word"), paste0(Stimuli2, "s"), Stimuli2),
         Stimuli = ifelse(Stimuli1 == Stimuli2, Stimuli1, 
                          paste(Stimuli1, Stimuli2, sep = "\nvs.\n")),
         Layout = ifelse(Layout1 == Layout2, Layout1,
                         paste(toTitleCase(Layout1), toTitleCase(Layout2), sep = "\nvs.\n")),
         Area = substr(Label, 18, 20)) %>% 
  select(-c(Stimuli1, Stimuli2, Layout1, Layout2))
```

##### Intact faces vs. words
```{r fig.width=6, fig.asp=1}
# save the df for intact English vs. intact Chinese
df_intact_LO_area <- filter(df_decode_LO_area, Layout == "intact") %>% 
  mutate(Stimuli = fct_rev(Stimuli))

dat_text_intact_LO_area <- data.frame(
  Stimuli = c("faces\nvs.\nwords", "English\nvs.\nChinese"),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces vs. characters", 
            "English speakers: \nEnglish words vs. Chinese characters"),
  x     = .5, # c(1.35, 1.6),
  y     = 1.05
)

# intact
plot_intact_LO_area <- ggplot(df_intact_LO_area, aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_intact_LO_area, aes(x = x, y = y, label = label), size = 4, fontface = "bold", hjust=0) + #
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
  NULL

# ggsave('plot_decode_LO_area_intact.pdf', plot_intact_LO_area, width = 8, height = 8)
plot_intact_LO_area
```

### Intact vs. exchange
```{r fig.width=6, fig.asp=2}
df_inex_LO_area <- df_decode_LO_area %>% 
  filter(str_detect(Stimuli, "vs.", negate = TRUE),
         Layout == "Intact\nvs.\nExchange")
df_inex_LO_area$Stimuli <- fct_relevel(df_inex_LO_area$Stimuli, "English", after = Inf)
df_inex_LO_area$Stimuli <- fct_relevel(df_inex_LO_area$Stimuli, "Chinese", after = Inf)

dat_text_inex_LO_area <- data.frame(
  Stimuli = levels(df_inex_LO_area$Stimuli),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_inex_LO_area$Stimuli),
  x     = .5, # c(1, 1.1, 1.2, 1.2),
  y     = 1.05
)

plot_inex_LO_area <- ggplot(df_inex_LO_area, aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(title = "Intact vs. Exchange", x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_LO_area, mapping = aes(x = x, y = y, label = label), size = 6, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_decode_LO_area_inex.pdf', plot_inex_LO_area, width = 8, height = 16)
plot_inex_LO_area
```

```{r fig.width=12, fig.asp=.5}

dat_text_inex_LO_area_lr_fw <- data.frame(
  Stimuli = levels(df_inex_LO_area$Stimuli)[1:2],
  Hemisphere = "left",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters"),
  x     = .5, # c(1, 1.1),
  y     = 1.05
)

plot_inex_LO_area_E1 <- ggplot(filter(df_inex_LO_area, Exp == "E1"), aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises Experiment 1
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_LO_area_lr_fw, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),    
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

dat_text_inex_LO_area_lr_ec <- data.frame(
  Stimuli = levels(df_inex_LO_area$Stimuli)[3:4],
  Hemisphere = "left",
  label = c("English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_inex_LO_area$Stimuli)[3:4],
  x     = .5, # c(1.1, 1.2),
  y     = 1.05
)

plot_inex_LO_area_E2 <- ggplot(filter(df_inex_LO_area, Exp == "E2"), aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises Experiment 2
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_LO_area_lr_ec, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_inex_LO_area_lr <- ggarrange(plot_inex_LO_area_E1, plot_inex_LO_area_E2, ncol = 2, 
                          # labels = c("", "Intact vs. Exchange"), 
                          # label.x = -0.36,
                          # label.y = 1,
                          font.label = list(size = 24))
# ggsave('plot_decode_LO_area_inex_lr.pdf', plot_inex_LO_area_lr, width = 15, height = 8)
plot_inex_LO_area_lr
```

### Top vs. bottom
```{r fig.width=6, fig.asp=2}
df_parts_LO_area <- df_decode_LO_area %>% 
  filter(str_detect(Stimuli, "vs.", negate = TRUE),
         Layout != "Intact\nvs.\nExchange") %>% 
  mutate(Stimuli = as_factor(Stimuli))
df_parts_LO_area$Stimuli <- fct_relevel(df_parts_LO_area$Stimuli, "English", after = Inf)
df_parts_LO_area$Stimuli <- fct_relevel(df_parts_LO_area$Stimuli, "Chinese", after = Inf)

dat_parts_inex_LO_area <- data.frame(
  Stimuli = levels(df_parts_LO_area$Stimuli),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"),
  x     = .5, # c(1, 1.1, 1.2, 1.2),
  y     = 1.05
)

plot_topbottom_LO_area <- ggplot(df_parts_LO_area, aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x", 
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(title = "Top vs. bottom; left vs. right", x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_parts_inex_LO_area, mapping = aes(x = x, y = y, label = label), size = 6, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
  NULL

# ggsave('plot_decode_LO_area_topbottom.pdf', plot_topbottom_LO_area, width = 8, height = 16)
plot_topbottom_LO_area
```


```{r fig.width=12, fig.asp=.5}

dat_text_tb_all_lr_E1 <- data.frame(
  Stimuli = levels(df_parts_LO_area$Stimuli)[1:2],
  Hemisphere = "left",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters"), # levels(df_parts_LO_area$Stimuli)[1:2],
  x     = .5, # c(1, 1.1),
  y     = 1.05
)

plot_topbottom_LO_area_E1 <- ggplot(filter(df_parts_LO_area, Exp == "E1"), aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises Experiment 1
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_tb_all_lr_E1, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

dat_text_tb_all_lr_E2 <- data.frame(
  Stimuli = levels(df_parts_LO_area$Stimuli)[3:4],
  Hemisphere = "left",
  label = c("English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_parts_LO_area$Stimuli)[3:4],
  x     = .5, # c(1.1, 1.2),
  y     = 1.05
)

plot_topbottom_LO_area_E2 <- ggplot(filter(df_parts_LO_area, Exp == "E2"), aes(y = mean, x = Area)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x", 
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = expression(paste("Lateral Occipital Label Area (", mm^2, ")")), y = "Accuracy") +  # set the names for main, x and y axises Experiment 2
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_tb_all_lr_E2, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_topbottom_LO_area_lr <- ggarrange(plot_topbottom_LO_area_E1, plot_topbottom_LO_area_E2, ncol = 2, 
                               # labels = c("", "Top vs. bottom; left vs. right"), 
                               # label.x = -0.6,
                               # label.y = 1,
                               font.label = list(size = 24))
# ggsave('plot_decode_LO_area_topbottom_lr.pdf', plot_topbottom_LO_area_lr, width = 15, height = 8)
plot_topbottom_LO_area_lr
```

# Plots
## Decoding
```{r warning=FALSE}
# combine all decoding results

df_decoding <- rbind(mutate(one_decode_agg_E1_FFA1, Exp = "E1", ROI = "FFA1"),
                     mutate(one_decode_agg_E1_FFA2, Exp = "E1", ROI = "FFA2"),
                     mutate(one_decode_agg_E1_VWFA, Exp = "E1", ROI = "VWFA"),
                     mutate(one_decode_agg_E1_LO, Exp = "E1", ROI = "LO"),
                     mutate(one_decode_agg_E2_FFA1, Exp = "E2", ROI = "FFA1"),
                     mutate(one_decode_agg_E2_FFA2, Exp = "E2", ROI = "FFA2"),
                     mutate(one_decode_agg_E2_VWFA, Exp = "E2", ROI = "VWFA"),
                     mutate(one_decode_agg_E2_LO, Exp = "E2", ROI = "LO")) %>% 
  separate(ClassifyPair, c("Stimuli1", "Layout1", "Stimuli2", "Layout2")) %>% 
  mutate(Stimuli1 = if_else(Stimuli1 %in% c("face", "word"), paste0(Stimuli1, "s"), Stimuli1),
         Stimuli2 = if_else(Stimuli2 %in% c("face", "word"), paste0(Stimuli2, "s"), Stimuli2),
         Stimuli = ifelse(Stimuli1 == Stimuli2, Stimuli1, 
                          paste(Stimuli1, Stimuli2, sep = "\nvs.\n")),
         Layout = ifelse(Layout1 == Layout2, Layout1,
                         paste(toTitleCase(Layout1), toTitleCase(Layout2), sep = "\nvs.\n"))) %>% 
  select(-c(Stimuli1, Stimuli2, Layout1, Layout2))

# df_decoding$ROI <- fct_relevel(df_decoding$ROI, "LO", after = Inf)
# xaxislabel <- strsplit(unique(df_0$Stimuli), "\nvs.\n")[[1]]

```

### All intact stimuli
```{r fig.width=6, fig.asp=1}
# save the df for intact English vs. intact Chinese
df_intact <- filter(df_decoding, Layout == "intact") %>% 
  mutate(Stimuli = fct_rev(Stimuli))

dat_text_intact_all <- data.frame(
  Stimuli = c("faces\nvs.\nwords", "English\nvs.\nChinese"),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces vs. characters", 
            "English speakers: \nEnglish words vs. Chinese characters"),
  x     = 0.5,
  y     = 1.05
)

# intact
plot_intact_all <- ggplot(df_intact, aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_intact_all, aes(x = x, y = y, label = label), hjust = 0, size = 4, fontface = "bold") + #
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    
    # remove the facet background color
    strip.text.x = element_text(size = 15),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
  NULL

# ggsave('plot_decode_all_intact.pdf', plot_intact_all, width = 8, height = 8)
plot_intact_all
```

### Intact vs. exchange
```{r fig.width=6, fig.asp=2}
df_inex <- df_decoding %>% 
  filter(str_detect(Stimuli, "vs.", negate = TRUE),
         Layout == "Intact\nvs.\nExchange")
df_inex$Stimuli <- fct_relevel(df_inex$Stimuli, "English", after = Inf)
df_inex$Stimuli <- fct_relevel(df_inex$Stimuli, "Chinese", after = Inf)

dat_text_inex_all <- data.frame(
  Stimuli = levels(df_inex$Stimuli),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_inex$Stimuli),
  x     = .5,
  y     = 1.05
)

plot_inex_all <- ggplot(df_inex, aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises title = "Intact vs. Exchange", 
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust = 0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_decode_all_inex.pdf', plot_inex_all, width = 8, height = 16)
plot_inex_all
```


```{r fig.width=12, fig.asp=.5}

dat_text_inex_all_lr_fw <- data.frame(
  Stimuli = levels(df_inex$Stimuli)[1:2],
  Hemisphere = "left",
  label = c("Chinese speakers: \nChinese faces", # intact vs. exchanged 
            "Chinese speakers: \nChinese characters"), # intact vs. exchanged levels(df_inex$Stimuli)[1:2],
  x     = .5,
  y     = 1.05
)

plot_inex_E1 <- ggplot(filter(df_inex, Exp == "E1"), aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises Experiment 1 title = "", 
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr_fw, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust = 0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),    
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

dat_text_inex_all_lr_ec <- data.frame(
  Stimuli = levels(df_inex$Stimuli)[3:4],
  Hemisphere = "left",
  label = c("English speakers: \nEnglish words", # intact vs. exchanged 
            "English speakers: \nChinese characters"), # intact vs. exchanged levels(df_inex$Stimuli)[3:4],
  x     = .5,
  y     = 1.05
)

plot_inex_E2 <- ggplot(filter(df_inex, Exp == "E2"), aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises Experiment 2 title = "", 
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr_ec, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust = 0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_inex_lr <- ggarrange(plot_inex_E1, plot_inex_E2, ncol = 2, 
                          # labels = c("", "Intact vs. Exchange"), 
                          # label.x = -0.36,
                          # label.y = 1,
                          font.label = list(size = 24))
# ggsave('plot_decode_all_inex_lr.pdf', plot_inex_lr, width = 15, height = 8)
plot_inex_lr
```


### Top vs. bottom
```{r fig.width=6, fig.asp=2}
df_parts <- df_decoding %>% 
  filter(str_detect(Stimuli, "vs.", negate = TRUE),
         Layout != "Intact\nvs.\nExchange") %>% 
  mutate(Stimuli = as_factor(Stimuli))
df_parts$Stimuli <- fct_relevel(df_parts$Stimuli, "English", after = Inf)
df_parts$Stimuli <- fct_relevel(df_parts$Stimuli, "Chinese", after = Inf)

dat_parts_inex_all <- data.frame(
  Stimuli = levels(df_parts$Stimuli),
  Hemisphere = c("left"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), #levels(df_parts$Stimuli),
  x     = .5, # c(1, 1.1, 1.2, 1.2),
  y     = 1.05
)

plot_topbottom_all <- ggplot(df_parts, aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x", 
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(title = "Top vs. bottom; left vs. right", x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_parts_inex_all, mapping = aes(x = x, y = y, label = label), size = 6, fontface = "bold", hjust = 0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
  NULL

# ggsave('plot_decode_all_topbottom.pdf', plot_topbottom_all, width = 8, height = 16)
plot_topbottom_all
```


```{r fig.width=12, fig.asp=.5}

dat_text_tb_all_lr_E1 <- data.frame(
  Stimuli = levels(df_parts$Stimuli)[1:2],
  Hemisphere = "left",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters"), #levels(df_parts$Stimuli)[1:2],
  x     = .5,
  y     = 1.05
)

plot_topbottom_E1 <- ggplot(filter(df_parts, Exp == "E1"), aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises Experiment 1
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_tb_all_lr_E1, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust =0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

dat_text_tb_all_lr_E2 <- data.frame(
  Stimuli = levels(df_parts$Stimuli)[3:4],
  Hemisphere = "left",
  label = c("English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), #levels(df_parts$Stimuli)[3:4],
  x     = .5,
  y     = 1.05
)

plot_topbottom_E2 <- ggplot(filter(df_parts, Exp == "E2"), aes(y = mean, x = ROI)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x", 
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  geom_hline(yintercept = 0.5, linetype = 5, alpha = 0.5) +  # add the line for 0.5 and 1 (y)
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0.4, 1.1)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises Experiment 2
  geom_text(aes(label = sig_ast(p)), size = 7, nudge_y = 0.15) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_tb_all_lr_E2, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 15), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_topbottom_lr <- ggarrange(plot_topbottom_E1, plot_topbottom_E2, ncol = 2, 
                               # labels = c("", "Top vs. bottom; left vs. right"), 
                               # label.x = -0.6,
                               # label.y = 1,
                               font.label = list(size = 24))
# ggsave('plot_decode_all_topbottom_lr.pdf', plot_topbottom_lr, width = 15, height = 8)
plot_topbottom_lr
```

## Univariate analysis
### Intact vs. exchange
```{r}
df_uni_ie <- rbind(mutate(desp_uni_E1_FFA1_ie, Exp = "E1", ROI = "FFA1"),
                   mutate(desp_uni_E1_FFA2_ie, Exp = "E1", ROI = "FFA2"),
                   mutate(desp_uni_E1_VWFA_ie, Exp = "E1", ROI = "VWFA"),
                   mutate(desp_uni_E1_LO_ie, Exp = "E1", ROI = "LO"),
                   mutate(desp_uni_E2_FFA1_ie, Exp = "E2", ROI = "FFA1"),
                   mutate(desp_uni_E2_FFA2_ie, Exp = "E2", ROI = "FFA2"),
                   mutate(desp_uni_E2_VWFA_ie, Exp = "E2", ROI = "VWFA"),
                   mutate(desp_uni_E2_LO_ie, Exp = "E2", ROI = "LO")) %>% 
  mutate(Stimuli = FaceWord,
         HemiROI = paste0(toTitleCase(substr(Hemisphere,1,1)), ROI))

df_uni_ie_sig <- rbind(mutate(as_tibble(simple_E1_lFFA1_ie), Exp = "E1", ROI = "FFA1", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_lFFA2_ie), Exp = "E1", ROI = "FFA2", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_VWFA_ie), Exp = "E1", ROI = "VWFA", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_lLO_ie), Exp = "E1", ROI = "LO", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lFFA1_ie), Exp = "E2", ROI = "FFA1", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lFFA2_ie), Exp = "E2", ROI = "FFA2", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_VWFA_ie), Exp = "E2", ROI = "VWFA", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lLO_ie), Exp = "E2", ROI = "LO", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_rFFA1_ie), Exp = "E1", ROI = "FFA1", Hemisphere = "right"),
                       mutate(as_tibble(simple_E1_rFFA2_ie), Exp = "E1", ROI = "FFA2", Hemisphere = "right"),
                       mutate(as_tibble(simple_E1_rLO_ie), Exp = "E1", ROI = "LO", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rFFA1_ie), Exp = "E2", ROI = "FFA1", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rFFA2_ie), Exp = "E2", ROI = "FFA2", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rLO_ie), Exp = "E2", ROI = "LO", Hemisphere = "right")) %>% 
  filter(FaceWord != ".") %>% 
  mutate(Stimuli = FaceWord,
         HemiROI = paste0(toTitleCase(substr(Hemisphere,1,1)), ROI),
         Layout = "intact") %>% 
  select(Exp, Layout, Stimuli, HemiROI, p.value) 

df_uni_ie <- left_join(df_uni_ie, df_uni_ie_sig) %>% 
  mutate(p.value = if_else(is.na(p.value), 1, p.value),
         Stimuli = as_factor(Stimuli)) 

df_uni_ie$Layout <- fct_relevel(df_uni_ie$Layout, "exchange", after = Inf)

```

```{r fig.width=6, fig.asp=2}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

dat_text_inex_all <- data.frame(
  Stimuli = levels(df_uni_ie$Stimuli),
  HemiROI = c("lFFA1"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_ie$Stimuli),
  x     = .5, # c(1, 1.1, 1.2, 1.2),
  y     = 2.65
)

plot_uni_inex_all <- ggplot(df_uni_ie, aes(y = emmean, x = Layout)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ HemiROI, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(title = "Intact vs. Exchange", x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65, nudge_x = 0.5) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all, mapping = aes(x = x, y = y, label = label), size = 7, fontface = "bold", hjust =0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_uni_all_inex.pdf', plot_uni_inex_all, width = 8, height = 16)
plot_uni_inex_all
```

```{r fig.width=6, fig.asp=2}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

dat_text_inex_all_ <- data.frame(
  Stimuli = levels(df_uni_ie$Stimuli),
  Hemisphere = "left",
  Layout = "intact",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_ie$Stimuli),
  x     = .5, #c(1, 1.1, 1.2, 1.2)-0.3,
  y     = 2.65
)

plot_uni_inex_all_ <- ggplot(df_uni_ie, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#C0C0C0", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(title = "Intact vs. Exchange", x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_, mapping = aes(x = x, y = y, label = label), size = 7, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    # axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_uni_all_inex.pdf', plot_uni_inex_all, width = 8, height = 16)
plot_uni_inex_all_
```

```{r fig.width=8, fig.asp=.75}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

df_uni_ie_1 <- filter(df_uni_ie, Stimuli %in% c("faces", "words")) %>% 
  droplevels()

dat_text_inex_all_lr1 <- data.frame(
  Stimuli = levels(df_uni_ie_1$Stimuli),
  Hemisphere = "left",
  Layout = "intact",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters"), # levels(df_uni_ie_1$Stimuli),
  x     = .5, # c(1, 1.1),
  y     = 2.65
)

plot_uni_inex_all_lr1 <- ggplot(df_uni_ie_1, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#CDCDC8", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(x = "ROIs", y = "Beta values") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr1, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 18),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 18), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

df_uni_ie_2 <- filter(df_uni_ie, Stimuli %in% c("English", "Chinese")) %>% 
  droplevels()

dat_text_inex_all_lr2 <- data.frame(
  Stimuli = levels(df_uni_ie_2$Stimuli),
  Hemisphere = "left",
  Layout = "intact",
  label = c("English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_ie_2$Stimuli),
  x     = .5, #c(1.1, 1.2),
  y     = 2.65
)

plot_uni_inex_all_lr2 <- ggplot(df_uni_ie_2, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#CDCDC8", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(x = "ROIs", y = "Beta values") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr2, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 18),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 18), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_uni_ie_lr <- ggarrange(plot_uni_inex_all_lr1, plot_uni_inex_all_lr2, ncol = 2, 
                              # labels = c("", "Intact vs. Exchange"), 
                              # label.x = -0.36,
                              # label.y = 1,
                              font.label = list(size = 24))

# ggsave('plot_uni_all_ie_lr.pdf', plot_uni_ie_lr, width = 15, height = 9)
plot_uni_ie_lr
```


### Top vs. bottom
```{r}
df_uni_tb <- rbind(mutate(desp_uni_E1_FFA1_tb, Exp = "E1", ROI = "FFA1"),
                   mutate(desp_uni_E1_FFA2_tb, Exp = "E1", ROI = "FFA2"),
                   mutate(desp_uni_E1_VWFA_tb, Exp = "E1", ROI = "VWFA"),
                   mutate(desp_uni_E1_LO_tb, Exp = "E1", ROI = "LO"),
                   mutate(desp_uni_E2_FFA1_tb, Exp = "E2", ROI = "FFA1"),
                   mutate(desp_uni_E2_FFA2_tb, Exp = "E2", ROI = "FFA2"),
                   mutate(desp_uni_E2_VWFA_tb, Exp = "E2", ROI = "VWFA"),
                   mutate(desp_uni_E2_LO_tb, Exp = "E2", ROI = "LO")) %>% 
  mutate(Stimuli = FaceWord,
         HemiROI = paste0(toTitleCase(substr(Hemisphere,1,1)), ROI))

df_uni_tb_sig <- rbind(mutate(as_tibble(simple_E1_lFFA1_tb), Exp = "E1", ROI = "FFA1", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_lFFA2_tb), Exp = "E1", ROI = "FFA2", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_VWFA_tb), Exp = "E1", ROI = "VWFA", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_lLO_tb), Exp = "E1", ROI = "LO", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lFFA1_tb), Exp = "E2", ROI = "FFA1", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lFFA2_tb), Exp = "E2", ROI = "FFA2", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_VWFA_tb), Exp = "E2", ROI = "VWFA", Hemisphere = "left"),
                       mutate(as_tibble(simple_E2_lLO_tb), Exp = "E2", ROI = "LO", Hemisphere = "left"),
                       mutate(as_tibble(simple_E1_rFFA1_tb), Exp = "E1", ROI = "FFA1", Hemisphere = "right"),
                       mutate(as_tibble(simple_E1_rFFA2_tb), Exp = "E1", ROI = "FFA2", Hemisphere = "right"),
                       mutate(as_tibble(simple_E1_rLO_tb), Exp = "E1", ROI = "LO", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rFFA1_tb), Exp = "E2", ROI = "FFA1", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rFFA2_tb), Exp = "E2", ROI = "FFA2", Hemisphere = "right"),
                       mutate(as_tibble(simple_E2_rLO_tb), Exp = "E2", ROI = "LO", Hemisphere = "right")) %>% 
  filter(FaceWord != ".") %>% 
  mutate(Stimuli = FaceWord,
         HemiROI = paste0(toTitleCase(substr(Hemisphere,1,1)), ROI),
         Layout = case_when(Exp == "E1" ~ "top",
                            Exp == "E2" ~ "partA")) %>% 
  select(Exp, Layout, Stimuli, HemiROI, p.value) 

df_uni_tb <- left_join(df_uni_tb, df_uni_tb_sig) %>% 
  mutate(p.value = if_else(is.na(p.value), 1, p.value),
         Stimuli = as_factor(Stimuli)) 

# df_uni_tb$Layout <- fct_relevel(df_uni_tb$Layout, "exchange", after = Inf)

```

```{r fig.width=6, fig.asp=2}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

dat_text_inex_all <- data.frame(
  Stimuli = levels(df_uni_tb$Stimuli),
  HemiROI = c("lFFA1"),
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_tb$Stimuli),
  x     = .5, # c(1, 1.1, 1.2, 1.2),
  y     = 2.65
)

df_uni_tb_all <- df_uni_tb %>% 
  mutate(Layout = case_when(Layout %in% c("top", "partA") ~ "Part 1",
                            Layout %in% c("bottom", "partB") ~ "Part 2"))

plot_uni_inex_all <- ggplot(df_uni_tb_all, aes(y = emmean, x = Layout)) +
  geom_col(position = "dodge", width = .5, fill = "#CDCDC8") +
  facet_grid(Stimuli ~ HemiROI, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.9)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises title = "Top vs. Bottom; Left vs. Right", 
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65, nudge_x = 0.5) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all, mapping = aes(x = x, y = y, label = label), size = 7, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    # plot.margin = margin(5, 170, 60, 40, unit = "pt"),
    text = element_text(colour="black"),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_uni_all_inex.pdf', plot_uni_inex_all, width = 8, height = 16)
plot_uni_inex_all
```

```{r fig.width=6, fig.asp=2}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

dat_text_inex_all_ <- data.frame(
  Stimuli = levels(df_uni_tb$Stimuli),
  Hemisphere = "left",
  Layout = "Part 1",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters", 
            "English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_tb$Stimuli),
  x     = .5, # c(1, 1.1, 1.2, 1.2)-0.3,
  y     = 2.65
)

plot_uni_inex_all_ <- ggplot(df_uni_tb_all, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#C0C0C0", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(title = "Top vs. Bottom; Left vs. Right", x = "ROIs", y = "Accuracy") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_, mapping = aes(x = x, y = y, label = label), size = 7, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    # axis.text.y = element_text(size = 13),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 13), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

# ggsave('plot_uni_all_inex.pdf', plot_uni_inex_all, width = 8, height = 16)
plot_uni_inex_all_
```

```{r fig.width=8, fig.asp=.75}
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "English", after = Inf)
# df_inex_uni$Stimuli <- fct_relevel(df_inex_uni$Stimuli, "Chinese", after = Inf)

df_uni_tb_1 <- filter(df_uni_tb_all, Stimuli %in% c("faces", "words")) %>% 
  droplevels()

dat_text_inex_all_lr1 <- data.frame(
  Stimuli = levels(df_uni_tb_1$Stimuli),
  Hemisphere = "left",
  Layout = "Part 1",
  label = c("Chinese speakers: \nChinese faces", 
            "Chinese speakers: \nChinese characters"), #levels(df_uni_tb_1$Stimuli),
  x     = .5, # c(1, 1.1),
  y     = 2.65
)

plot_uni_inex_all_lr1 <- ggplot(df_uni_tb_1, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#CDCDC8", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(x = "ROIs", y = "Beta values") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr1, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 18),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 18), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

df_uni_tb_2 <- filter(df_uni_tb_all, Stimuli %in% c("English", "Chinese")) %>% 
  droplevels()

dat_text_inex_all_lr2 <- data.frame(
  Stimuli = levels(df_uni_tb_2$Stimuli),
  Hemisphere = "left",
  Layout = "Part 1",
  label = c("English speakers: \nEnglish words", 
            "English speakers: \nChinese characters"), # levels(df_uni_tb_2$Stimuli),
  x     = .5, # c(1.1, 1.2),
  y     = 2.65
)

plot_uni_inex_all_lr2 <- ggplot(df_uni_tb_2, aes(y = emmean, x = ROI, fill = Layout)) +
  geom_col(position = "dodge", width = .5) + # , fill = "#CDCDC8"
  scale_fill_manual(values = c("#CDCDC8", "#A9A9A9")) +
  facet_grid(Stimuli ~ Hemisphere, scales = "free_x", space = "free_x", 
             switch = "x",
             labeller = labeller(Hemisphere = c(left = "left hemisphere", right = "right hemisphere"))) +
  geom_errorbar(mapping = aes(ymin = lower.CL, ymax = upper.CL), linetype = 1,  # set the error bar
                show.legend = FALSE, width = 0.25, alpha = .5,
                position = position_dodge(width=0.5)) +
  # scale_x_discrete(labels = toTitleCase(df_0$Stimuli)) +
  # scale_y_continuous(expand= c(0, 0), breaks = seq(0, 1, .25)) +  # remove the space between columns and x axis
  coord_cartesian(ylim = c(0, activationUL)) +
  labs(x = "ROIs", y = "Beta values") +  # set the names for main, x and y axises
  geom_text(aes(label = sig_ast(p.value)), size = 7, nudge_y = 0.65) + # add starts to the significant columns
  # geom_text(aes(label = round(mean, 2)), size = 4, nudge_y = 0.2) +
  geom_text(data = dat_text_inex_all_lr2, mapping = aes(x = x, y = y, label = label), size = 4.5, fontface = "bold", hjust=0) +
  theme_bw() +
  theme(
    plot.title = element_text(lineheight=.8, face="bold", size = 24, hjust = 0.5, vjust = -1),
    text = element_text(colour="black", size = 18),
    axis.text = element_text(colour="black"),
    axis.text.x = element_text(face = "bold", size = 16),
    axis.text.y = element_text(size = 18),
    axis.title.x = element_text(face = "bold", size = 20), # the size of the texts in plot
    axis.title.y = element_text(size = 17, vjust = 2.5), # the size of the texts in plot
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'), # , arrow = arrow(length = unit(0.3, "cm"))
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.position = "bottom",
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.spacing = unit(1.5, "lines"),
    # remove the facet background color
    strip.text.x = element_text(size = 18), # element_blank(),
    strip.text.y = element_blank(),
    strip.background = element_blank(),
    strip.placement = "outside",
  ) +
NULL

plot_uni_tb_lr <- ggarrange(plot_uni_inex_all_lr1, plot_uni_inex_all_lr2, ncol = 2, 
                              # labels = c("", "Top vs. Bottom; Left vs. Right"), 
                              # label.x = -0.6,
                              # label.y = 1,
                              font.label = list(size = 24))

# ggsave('plot_uni_all_tb_lr.pdf', plot_uni_tb_lr, width = 15, height = 9)
plot_uni_tb_lr
```

# Versions of packages used
```{r versions}
# rstudioapi::versionInfo()
sessionInfo()
```
